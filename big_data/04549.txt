6
1
0
2

 
r
a

 

M
5
1

 
 
]

G
L
.
s
c
[
 
 

1
v
9
4
5
4
0

.

3
0
6
1
:
v
i
X
r
a

Know Your Customer: Multi-armed Bandits with

Capacity Constraints

Ramesh Johariâˆ—

Vijay Kambleâ€ 

Yash Kanoriaâ€¡

Abstract

A wide range of resource allocation and platform operation settings exhibit the
following two simultaneous challenges: (1) service resources are capacity constrained;
and (2) clientsâ€™ preferences are not perfectly known. To study this pair of challenges,
we consider a service system with heterogeneous servers and clients. Server types are
known and there is ï¬xed capacity of servers of each type. Clients arrive over time, with
types initially unknown and drawn from some distribution. Each client sequentially
brings N jobs before leaving. The system operator assigns each job to some server
type, resulting in a payoï¬€ whose distribution depends on the client and server types.
Our main contribution is a complete characterization of the structure of the opti-
mal policy for maximization of the rate of payoï¬€ accumulation. Such a policy must
balance three goals: (i) earning immediate payoï¬€s; (ii) learning client types to increase
future payoï¬€s; and (iii) satisfying the capacity constraints. We construct a policy
that has provably optimal regret (to leading order as N grows large). Our policy has
an appealingly simple three-phase structure: a short type-â€œguessingâ€ phase, a type-
â€œconï¬rmationâ€ phase that balances payoï¬€s with learning, and ï¬nally an â€œexploitationâ€
phase that focuses on payoï¬€s. Crucially, our approach employs the shadow prices of
the capacity constraints in the assignment problem with known types as â€œexternality
pricesâ€ on the serversâ€™ capacity.

1

Introduction

Our paper considers the interaction between two central operational challenges for almost
any platform: one one hand, new users are continuously arriving, and the platformâ€™s goal is
to learn the preferences of these new users quickly enough to ensure satisfactory outcomes for
them. On the other hand, learning preferences typically requires actually serving customers,
and observing the outcomes. This is a complex undertaking because there may be limited
inventory available with which to serve customers. Thus the platform faces a fundamental

âˆ—Stanford University (rjohari@stanford.edu)
â€ Stanford University (vjkamble@stanford.edu)
â€¡Columbia Business School (ykanoria@gsb.columbia.edu)

1

exploration-exploitation tradeoï¬€. It can either â€œexploitâ€ existing knowledge, serving users
with the goal of maximizing surplus given current information; or it can â€œexploreâ€ to gain
additional knowledge, serving users with the explicit goal of learning preference information.
In this paper we address the correct balance between these activities in the presence of
inventory constraints.

There are many examples where learning and inventory constraints interact; as one mo-
tivating example, consider the case of online fashion retailers such as Stitch Fix and Trunk
Club. When a new client arrives, she has preferences regarding desired clothing, some of
which are declared as part of a proï¬le, but many of which are qualitative. For simplicity,
imagine that there are two types of client types: some want professional clothing (â€œbusiness
typeâ€), and others want casual clothing (â€œcasual typeâ€); but the platform does not know
which is which when the client ï¬rst arrives. In addition, suppose that the platform has two
types of shirts available: high-end blue shirts that is equally at home in either a business or
casual setting, and red shirts that are decidedly casual. Finally, suppose that the blue shirts
are preferred by both types of users to the red shirts; and the platform knows this.

What does the platform do? If there are no inventory constraints the decision is simple:
send any new incoming customer blue shirts, without attempting to learn her type. But now
suppose inventory is constrained; in particular, suppose blue shirts are in short supply. This
means some users will not be able to receive their preferred choice: clearly, in this case the
platform is better oï¬€ sacriï¬cing some of the surplus of the casual type clients, and sending
them red shirts instead. But in order to do this, the platform needs to know the client is
casual type! This can only be learned by sending the red shirts to users to actually learn
their type; in the process, regret is incurred on any customers that are of the business type,
as they are likely to return clothes they do not want.

The stylized problem described here is in fact a general instance of a phenomenon that
arises in a wide array of service systems. To varying degrees, the same challenge can be
found not only in other online retail settings, but also in online labor markets (such as
Upwork), marketplaces for goods (such as eBay or Etsy), and markets for local tasks (such
as TaskRabbit). Working with a model that captures the essential features of the resource
allocation problem described above, our paper both characterizes the aggregate payoï¬€ the
platform can achieve, and delivers an algorithm that achieves it.

The model we consider has two â€œsidesâ€: clients and servers (e.g., the diï¬€erent types of
inventory above). Clients arrive and depart over time, and sequentially bring jobs during
their lifetime. For each job, the platform can select an available server to match the job; once
the match is made, a (random) payoï¬€ is generated and observed by the platform, and the
server (temporarily) becomes unavailable. (In the retail example above, this might be the
time required to restock the item.) The platform learns about the clientâ€™s preferences based
on the observed payoï¬€s; the overall goal is to maximize aggregate surplus from matches.

We make three assumptions to simplify our algorithmic development. First, servers are
typically known better by the platform than clients, since servers have many more observable
transactions from which to infer type; this is the case for all the examples above. Therefore we
assume server types are known, while client types must be learned. Second, we assume that

2

the platform centrally controls matching; and third, we assume that there are no strategic
considerations. These modeling choices allow us to focus on the algorithmic challenge of
learning and matching while meeting capacity constraints.

Our main contribution is a simple and practical scheme to maximize aggregate surplus
when client types must be learned in the presence of capacity constraints. A key to our
approach is to leverage shadow prices on the capacity constraints in the optimization problem
with known client types; these prices are quite naturally â€œexternality pricesâ€ on servers. Thus
we use the following design approach: for each server, we lower rewards according to the
externality prices, and execute a learning algorithm individually on a client-by-client basis
ignoring the capacity constraint. Note that the resulting problem at the individual client
level becomes a multiarmed bandit (MAB) problem [1].

Nominally, this approach should be eï¬€ective in managing capacity, since the externality
prices exactly account for the capacity constraint in the problem with known types. How-
ever, it quickly becomes apparent that externality pricing alone is insuï¬ƒcient as a solution.
Informally, the issue is that there can be signiï¬cant capacity violations unless matching is
carefully directed: in general, indiï¬€erences between servers occur generically even when client
types are known, and a capacity-agnostic MAB algorithm would not know how to resolve
them appropriately. For this reason, despite the correct externality prices, the allocation
of clients to servers can still be very diï¬€erent from the optimal (and in particular feasible)
allocation when client types are known.

Our scheme addresses this challenge by separating the resource allocation problem prob-
lem into three phases: â€œguessingâ€ the client type, â€œconï¬rmingâ€ the client type (balancing
learning and surplus maximization) , and â€œexploitation.â€ Most of our algorithmic contribu-
tion lies in careful design of the conï¬rmation and exploitation phases. For the former, we
optimally tradeoï¬€ learning and payoï¬€ maximization, but largely ignore capacity constraints
(except for the eï¬€ect of the externality prices). In the exploitation phase, we carefully design
the allocation algorithm to minmize capacity violations. In particular, our design ensures
that exploitation accounts for 1 âˆ’ o(1) of all jobs (as the number of jobs grows), so that any
capacity violations remain o(1), and we show how to eliminate these costlessly by slightly
modifying the tie-breaking rules in the exploitation phase.

The scheme we develop is also particularly appealing from a practical standpoint, because
it suggests two very natural changes platforms could make painlessly to dramatically improve
their inventory management. First, compute externality prices for each type of server. While
this might seem computationally complex, in platforms such as those described above, rea-
sonable proxies abound; for example, Stitch Fix might employ a monotone function of the
remaining inventory as a proxy for the externality price on a given item. Second, separation
the guessing and conï¬rmation phases from the exploitation phase is natural in an online
platform: most platforms have an â€œonboardingâ€ period for each user, and during this pe-
riod exploration of the userâ€™s type is reasonable; our algorithmic design suggests a viable
approach to balancing surplus maximization, capacity constraints, and learning during the
onboarding period.

As platforms continue to scale, they will increasingly face the challenge of integrating

3

new users while managing their limited inventory.
If they allocate indiscriminately while
ignoring capacity constraints, the constraints will bind and the platform will be stocked out,
with large opportunity costs in lost transaction; on the other hand, without learning quickly
enough about new clients, the platform may leave signiï¬cant revenue on the table. Since all
online market platforms focus on growth through acquisition of new users, properly meeting
the challenge we study here is fundamental to their success. Our work is a signiï¬cant step
towards providing practical algorithmic approaches to this challenge with provably optimal
performance. More broadly, as we discuss further in the conclusions, we believe our work can
form the foundation for understanding a range of open issues at the intersection of learning
and matching.

The remainder of the paper is organized as follows. After discussing related work in
Section 2, we present our model in Section 3.
In Section 4, we outline the optimization
problem of interest to the platform (in a continuum limit where the mass of clients and
servers grows large). In Section 5 we outline the straightforward idea of employing externality
prices. In Section 6, we present our algorithm and main theorem regarding its performance.
In particular, we show that our algorithm attains optimal regret in the limit where each
client brings many jobs, and sketch its proof. We conclude in Section 7.

2 Related literature

Our problem setting combines two challenges that have each been extensively studied on their
own in the literature: (1) maximizing reward while learning; and (2) a dynamic assignment
problem of clients to servers, when there is no type uncertainty. We now describe each of
these lines of work in turn, as well as their relationship to our contribution.

Maximizing reward while learning is exempliï¬ed by the multi-armed bandit (MAB) prob-
lem [19, 26, 10]. The learning problem in our setting corresponds to a MAB problem that has
been studied in [1] (see [2] for a generalized model). In the standard stochastic MAB model
introduced by [30], there are a ï¬xed number of arms that yield a random reward on each pull
with an unknown distribution, and the problem is to deï¬ne an adaptive policy for choosing
the arms that minimizes regret (the diï¬€erence between the policyâ€™s expected average reward
and the expected reward of the best arm). The optimal regret in this case was shown to
be O((log N )/N ) and several policies that achieve this bound are now known [11, 6].
In
the particular problem studied in [1], the uncertainty in the rewards of the diï¬€erent arms is
ï¬nitely parametrized, with diï¬€erent arms being optimal for diï¬€erent parameter values. This
introduces correlation in the rewards of the arms, and depending on certain identiï¬ability
conditions, the optimal regret is either O(1/N ) or O((log N )/N ).

The dynamic assignment problem with known types plays a key role in our analysis,
because we use it to compute â€œexternality pricesâ€ on the servers that help correctly account
for capacity constraints. To compute these prices, an important step is to resort to a con-
tinuum scaling [21, 32, 33] of a dynamic assignment model with stochastic arrivals. In this
ï¬‚uid limit, when types are known, the dynamic assignment problem simpliï¬es to a certain
linear program that is closely related to the static planning problem in stochastic processing

4

networks; see [9] and references therein. In the static planning problem corresponding to
our setting with known types, a ï¬nite number of types of jobs arrive at certain rates into
the system, which are to be processed by a ï¬nite number of types of servers in some order,
each of which has a ï¬xed service rate. The static planning problem in [9] focuses on char-
acterization of the set of arrival rate vectors that can be supported by the system. In our
case, there is a (client and server type dependent) payoï¬€ generated from each match, and
the problem is to allocate jobs to servers to maximize the rate of value generation, subject
to server capacity constraints. In this form, the problem can also be viewed as a version of
the assignment problem due to Shapley and Shubik [38], in which the resources (the service
rates) are divisible. We also note that a related class of dynamic resource allocation prob-
lems, online bipartite matching, is also well studied in the computer science community; see
[35] for a survey.

A diï¬€erent class of models capturing MAB problems with constraints called â€œBandits
with knapsacksâ€ has been studied in the recent years. [15] formalized the basic model, which
subsumed several related problems that had appeared in literature on revenue management
under demand uncertainty [17, 18, 37, 40, 12], and budgeted dynamic procurement [14, 39].
The formulation is same as the classical MAB problem due to Lai and Robbins, with the
diï¬€erence being that every pull of an arm depletes a vector of resources which are limited
in supply. Subsequently, after a series of extensions [16, 3], the model has been ultimately
generalized to the contextual bandit setting of [31] and the linear contextual bandits setting
of [20], where the reward functions and the constraints are concave and convex respectively
in the space of outcomes [5, 4]. There is considerable diï¬€erence between our setting and
these models. These settings consider a single MAB problem over a ï¬xed time horizon, with
observable contexts arriving sequentially. Our setting on the other hand can be seen as a
system where diï¬€erent types of MAB problems arrive over time at certain (known) rates,
which are coupled by the resource constraints that are needed to be satisï¬ed on an average
across all these arriving problems. These types correspond to the â€œtypesâ€ of the arriving
clients, which are unknown at arrival but belong to a ï¬nite set, while the reward distribution
for each client type and server pair is known. Hence, as mentioned earlier, the uncertainty
in each arriving bandit problem is ï¬nitely parameterized, which is again a departure from
the kind of bandit problems considered in these models.

We conclude by discussing some other directions of work that are related to this paper.
Our work has particular relevance to two-sided dynamic matching markets, where clients
and/or resources arrive over time and allocations must be made online [7, 8, 13, 27]. There
have been some recent works that consider multi-period matching in the stable-marriage
setting, in which the agentsâ€™ preferences can evolve over time [28, 22, 29]. The main con-
tribution of these works is the analysis of dynamic notions of stability in such settings. [23]
study a two-sided dating market, where the men and women date each other repeatedly to
learn about their preferences over time. They model the situation as a two-sided multi-armed
bandit problem and empirically study the asymptotic stability properties of some natural
matching mechanisms combined with a simple Îµ-greedy learning scheme. A recent work
[25] also studies matching with learning, mediated by a central platform; a key diï¬€erence

5

from our work is that they have no constraints on the number of matches per agent. Agent
incentives are considered, and optimal matching rules are studied under proï¬t maximization
and welfare maximization.

Finally, a recent work [34] studies a pure learning problem in a setting very similar to
ours with capacity constraints on each type of server/expert. Experts purely serve to help
learn the label of each job (corresponding to our clients). The paper characterizes the set of
arrival rates that can be supported by the given service capacity, while achieving the learning
objective on each job. The analysis and result are related to our own work in that they are
asymptotic, and use a (diï¬€erent) linear program in developing a near optimal assignment
policy (albeit with o(1) violations of capacity).

3 The model

We consider a benchmark model of a centralized two-sided platform that dynamically learns
about its user population and makes matches over time. The details of our model are as
follows.

1. Clients, servers, and jobs. For convenience we adopt the terminology of clients and
servers to describe the two sides of the market. As noted in the introduction, we assume a
ï¬xed set of servers whose types are known; arrivals and type uncertainty are captured on
the client side of the market. Let C denote the set of possible client types and S denote the
set of possible server types. Clients of type i arrive at rate Ï(i), and there are n(s) servers
of type s.1 When a client arrives, her type i âˆˆ C is initially unknown.

Each client brings N jobs sequentially (before leaving). The marketplace matches each
arriving job to an available server type. Upon being matched with a job from a client of
type i, a server of type s becomes unavailable for a time Exponential(Âµ(s)), after which the
server is again available to match.2 We also allow a job to not be matched to any server,
implying that it is lost. In this case, we will formally think of that job as being directed
to an additional server type Îº that has an unbounded number of servers, i.e., n(Îº) = âˆ.
W.l.o.g., assume that Îº is included in S. We use Â¯Âµ(s) = n(s)Âµ(s) to denote the eï¬€ective
service rate of server type s, i.e., the maximum rate at which servers of type s can provide
service.

arrival rate of jobs in the system is(cid:80)

We deï¬ne Ï(i) = Ï0(i)/N for some base arrival rates Ï0(i) so that in eï¬€ect, the total
iâˆˆC Ï0(i). This allows us to consider matching problems
parameterized by N and study their solutions as N varies. Note that Ï0(i) = N Ï(i) is the
overall rate of arrival of jobs to the system from client type i.

1As noted in the following subsection, we work in a continuum model, meaning that a mass Ï(i) of clients

of type i arrive per unit time, and similarly, n(s) is the mass of servers of type s.

2Note in general, Âµ may depend on both the server and client type. However, making Âµ depend only s

ensures that the busy time is not indicative of our client type, which simpliï¬es analysis.

6

2. Payoï¬€s. The payoï¬€ from assigning a job to a server depends only on the type i of
the client bringing the job and the type s of the server. In particular, we assume that the
payoï¬€ is an independent Bernoulli(A(i, s)), for some matrix A; a job that goes unmatched
earns zero payoï¬€ (i.e., A(i, Îº) = 0 for all i âˆˆ C). Thus, there is uncertainty in payoï¬€ both
because the type i is uncertain, and because of randomness in payoï¬€s conditioned on the
pair of types. Thus we have the central beneï¬t of exploration: learning about a clientâ€™s type
is valuable because it helps generate higher payoï¬€s from jobs that the same client brings in
future. Note that we think of payoï¬€ as accruing to the system overall, without considering
how it is divided between the client, server and the platform.

3. What does the platform know? Our knowledge assumptions on the platform are moti-
vated by settings where there is a reasonable installed user base already, so that the emphasis
is not on the â€œcold startâ€ problem. In this setting, aggregate statistics about the platform
are known: in particular, we assume the platform knows n(s) and Âµ(s), as well as the rates
Ï(i) and Âµ(i) corresponding to each client type i. In addition we assume the platform knows
the client lifetime number of jobs N . Finally, we assume the compatibility matrix A is known
â€“ this applies to a platform that has already learned how payoï¬€s depend on client and server
types, but does not know the type of a new client when she brings her ï¬rst job. This reï¬‚ects
the most salient issue for a platform that has a reasonable installed user base: it is relatively
easier to estimate how well diï¬€erent types might be compatible with each other (indeed,
platforms already do this well on a regular basis), than to correctly determine the type of
any speciï¬c new user.

The central challenge in this model is the following. Since clients are arriving and de-
parting, and the platform does not know the type of any individual client, the market must
constantly learn the types of new clients in order to maximize future payoï¬€s generated by
those clientsâ€™ jobs. We develop an optimal matching policy to balance exploration and
exploitation, and thus maximize long-run aggregate payoï¬€.

4 The dynamic assignment problem: A continuum limit

In this section we precisely state the optimization problem we study. We use a continuum
(ï¬‚uid) scaling [21, 32, 33] to simplify analysis of our model, and obtain guidance on the design
of optimal matching strategies for the platform. This corresponds to the limit of the system
in which the number of servers and the client arrival rates Ï0(i) are both simultaneously

7

scaled up to âˆ.3,4 Further, we consider stationary ergodic assignment policies, i.e., policies
such that the system state has stationary long-run behavior. We measure the performance
of a policy by the steady-state rate of payoï¬€ accumulation.

Consider a stationary ergodic policy. The policy induces a function Ï€ from the history of
a client (who arrives while the system is in steady-state) to a distribution of the type of server
her t-th job will be assigned to. The history Ht consists of, for each of the previous tâˆ’1 jobs,
the server type it was assigned to, and the payoï¬€ that was generated. Formally, any policy for
routing N jobs from each client induces a steady-state mapping Ï€ : (S Ã— {0, 1})tâˆ’1 â†’ âˆ†(S)
for all t = 1, 2, . . . , N .

Clearly, any Ï€ further induces a fraction of jobs Î¾Ï€(i, s) generated by a client of type i
that are served by a server of type s. Then the rate at which servers of type s serve jobs
from clients of type i is Ï(i)N Î¾Ï€(i, s) = Ï0(i)Î¾Ï€(i, s). The capacity constraint can now be
captured as follows:

Ï0(i)Î¾Ï€(i, s) â‰¤ Â¯Âµ(s)

âˆ€s âˆˆ S .

(1)

(cid:88)

iâˆˆC

policy Ï€ is given by(cid:80)

The expected payoï¬€ that results from jobs associated with a single client of type i under
sâˆˆS Î¾Ï€(i, s)A(i, s). Since jobs arrive from clients of type i at a rate of

Ï(i)N = Ï0(i), the overall steady state rate of payoï¬€ accumulation is

(cid:88)

iâˆˆC

(cid:88)

sâˆˆS

Ï0(i)

Î¾Ï€(i, s)A(i, s) ,

Our objective is to ï¬nd a policy Ï€ that maximizes this rate.

We focus on policies that allocate jobs from a client to servers based only on the history
of that client; this choice is without loss of generality, as we now show. In general, a policy
can base its assignment decision for a job not just on the history of the particular client,
but on the entire history (including the current state) of the entire system. Notice, however,
that for any Ï€ induced by some stationary policy, there is a very simple policy that induces
the same Ï€ and satisï¬es the capacity constraints, but makes assignment decisions based only
on the history of the client. The policy simply assigns the t-th job of a client with history
Ht to a server type drawn from the distribution Ï€(Ht). Since (1) holds, we deduce that a

3Our continuum model is the correct limiting description of the ï¬nite system because we are thinking of
the number of servers of each type as scaling up, as opposed to the service rate scaling up. In the latter
case, there is a positive probability that a job may ï¬nd all the servers of a particular type occupied even in
the limit, irrespective of whether the servers are operating at full capacity or not. On the other hand in our
model, with the number of servers scaling up, the probability that a job ï¬nds all the servers of a particular
type occupied vanishes in the limit. This holds even in the case where all the servers are operating at full
capacity and hence the fraction of time an individual server idles can be zero.

4Strictly speaking, in the continuum limit we interpret A(i, s) not as the expected payoï¬€ from a single job
(which would lead to inï¬nite total payoï¬€), but the payoï¬€ from a unit mass of jobs of client type i assigned
to server type s. This is just an appropriate â€œscalingâ€ of the payoï¬€ per job to arrive at the desired limit,
and does not alter the learning problem for a single client. Hence, we will continue to think of the payoï¬€
from a single job as being Bernoulli(A(i, s)) in the context of learning client types.

8

server of the drawn type will be available with probability 1, in steady state. It follows that
the policy induces the same Ï€ (and hence produces the same rate of payoï¬€ accumulation).
Thus, it is convenient to identify each Ï€ with the corresponding simple policy, and restrict
our study (at no cost in terms of our objective) to the class of such policies Î N , that choose
a server type for each job based only on the history of the client.5

Let Î¾Ï€ = [Î¾Ï€(i, s)]CÃ—S. This is a (right) stochastic matrix since each row sums to 1. We

call this the routing matrix corresponding to a policy Ï€. Let

(cid:26)

(cid:27)

ÎN =

Î¾Ï€ : Ï€ âˆˆ Î N

âŠ† [0, 1]|C|Ã—|S|

be the set of achievable routing matrices (when each client brings N jobs).
We start by summarizing a few properties of ÎN in order to provide intuition for the
structure of this set. For simplicity, we consider a case with just two client types C = {i, i(cid:48)}
in describing these properties.

1. ÎN is a convex set, since since any convex combination of Â¯Î¾ âˆˆ ÎN and Â¯Î¾(cid:48) âˆˆ ÎN can be
achieved by appropriate randomization between the corresponding policies. In fact, ÎN is a
convex polytope (see Proposition 8.8 in the Appendix).

2. The projection of ÎN to the dimensions Î¾(i,Â·) is a subset of the probability simplex.

It is identical to the simplex in the absence of capacity constraints.

3. If types i and i(cid:48) cannot be distinguished (because they generate the same payoï¬€s),

then we must have Î¾(i,Â·) = Î¾(i(cid:48),Â·).

4. If types i and i(cid:48) can be distinguished then this allows for Î¾(i,Â·) (cid:54)= Î¾(i(cid:48),Â·). In the absence
of capacity constraints, limNâ†’âˆ ÎN converges to the product of probability simplices, one
for i and another for i(cid:48).

Now we can state the optimization problem we solve. The overall problem of choosing a

policy Ï€ to maximize the rate of accumulation of payoï¬€ is:

W N = max

s.t.

Î¾(i, s)A(i, s)

Ï0(i)
Ï0(i)Î¾(i, s) â‰¤ Â¯Âµ(s) âˆ€ s âˆˆ S;

sâˆˆS

(2)

(cid:88)

(cid:88)
(cid:88)

iâˆˆC

iâˆˆC
Î¾ âˆˆ ÎN .

Since ÎN is a convex polytope, this is a linear program, albeit a complex one. The complexity
of this problem is hidden in the complexity of the set ÎN , which includes all possible routing
matrices that can be obtained using policies in Î N .6 The remainder of our paper is devoted
to solving this problem and characterizing its value, by considering an asymptotic regime
where N â†’ âˆ.

5Notice that our argument also establishes that allowing waiting is not beneï¬cial: we can assume that
jobs must be served immediately or be dropped, with no eï¬€ect on the rate of payoï¬€ accumulation.
6Notice in particular that a policy allows for independently choosing â„¦(2N ) distributions over S.

9

5 Our approach: Pricing the capacity constraints

In this section we introduce prices on each server type (externality prices), derived from the
problem of maximizing the rate of payoï¬€ accumulation when client types are known. These
prices are exactly the optimal dual variables corresponding to the capacity constraints in
this optimization problem. We will now describe the problem with known types, and then
our approach of incorporating these prices into the problem with unknown types (studied in
the limit of large N ).

5.1 Known client types
Let D denote the set of achievable routing matrices when client types are known, deï¬ned as:

(cid:26)

The steady state payoï¬€ maximization problem with known client types is the following:

D =

x âˆˆ R|C|Ã—|S| : x(i, s) â‰¥ 0;

x(i, s) = 1

.

(cid:27)

(cid:88)

sâˆˆS

(cid:88)

V âˆ— = max

(cid:88)
(cid:88)

iâˆˆC

s.t.
iâˆˆC
x âˆˆ D.

x(i, s)A(i, s)

Ï0(i)
Ï0(i)x(i, s) â‰¤ Â¯Âµ(s) âˆ€ s âˆˆ S;

sâˆˆS

(3)

(4)

This linear program is a special case of the â€œstatic planning problemâ€ that has arisen fre-
quently in the operations literature (see, e.g. [9]). The optimal solution is a routing matrix
xâˆ—, which is a stochastic matrix (i.e., all row sums are one). Note that an optimal policy
(with known types) can easily be constructed from xâˆ—: the policy simply routes each job
from a client of type i to a server drawn independently from the distribution xâˆ—(i,Â·).
Now let pâˆ—(s)sâˆˆS be the shadow prices corresponding to the server capacity constraints
in V âˆ—. Formally, these are obtained from an optimal solution to the dual of problem V âˆ—.
Intuitively, these shadow prices capture the negative externality per unit of jobs that are
assigned to server type s. Note that both pâˆ— and xâˆ— can be easily computed, given the
primitives.

Our next proposition shows these prices are uniquely determined under a mild condition,

given as follows.

Deï¬nition 1. We say that arrival rates (Ï0(i))iâˆˆC and service rates (Â¯Âµ(s))sâˆˆS satisfy the
generalized imbalance condition if there is no pair of non-empty subsets of clients and servers
(C(cid:48),S(cid:48)), such that the total job arrival rate of C(cid:48) exactly matches the total eï¬€ective service

rate of S(cid:48). Formally, (cid:88)

(cid:88)

sâˆˆS(cid:48)

Ï0(i) (cid:54)=

iâˆˆC(cid:48)

Â¯Âµ(s) âˆ€Ï† (cid:54)= C(cid:48) âŠ† C, Ï† (cid:54)= S(cid:48) âŠ† S .

10

The generalized imbalance condition holds generically.7 Note that this condition does

not depend on the expected payoï¬€ matrix A.

We have the following result.

Proposition 5.1. Under the generalized imbalance condition, the server shadow prices pâˆ—
are uniquely determined.

The optimal externality-adjusted payoï¬€ of user i is:

U (i) = max

sâˆˆS A(i, s) âˆ’ pâˆ—(s);

and the set of optimal server types for user i is:
S(i) = arg max

sâˆˆS A(i, s) âˆ’ pâˆ—(s).

(5)

(6)

A standard duality argument demonstrates that in an optimal solution (with known types),
jobs from client type i are directed towards server types who generate the maximum expected
payoï¬€ after adjusting for the shadow price of the server type. Formally it can be shown that
xâˆ—(i,Â·) is supported on S(i). We remark that

Remark 2. Under generalized imbalance and if there is at least one server type that is being
used to capacity (in some xâˆ—), then there is at least one customer type i such that S(i) is not
a singleton: thus optimal routing requires properly allocating jobs between diï¬€erent servers
that are optimal for the same client (in other words, optimal tie-breaking is necessary), even
given the externality prices.

5.2 Unknown client types: The large N regime

We now return to problem (2). We quantify the performance of a policy for our problem (2)
in terms of its regret (this is any policy in Î N that respects capacity constraints), which we
deï¬ne as the amount by which its rate of accumulation of payoï¬€ is less than the maximum
rate V âˆ— achievable with known client types (problem 4). We will say that a policy is regret-
optimal if it achieves the smallest possible regret to leading order, asymptotically in N .

As noted above, we study (2) in the large N regime, where each client brings many jobs to
the system. Informally, in this limit, the platform should learn the client type early in their
lifetime; therefore it is natural to expect the optimal prices pâˆ—(s) to be â€œcloseâ€ to optimal
shadow prices in (2). This observation motivates our approach: Eliminate the capacity
constraints in (2) by replacing A(i, s) with â€œexternality-adjusted payoï¬€sâ€ A(i, s) âˆ’ pâˆ—(s).
The idea is that if pâˆ—(s) were the correct optimal dual variables, then the resulting solution,
so long as any tie-breaking is done appropriately to meet capacity constraints, would in fact

7The set of job arrival and eï¬€ective service rate vectors for which the condition holds is open and dense

, where R++ denotes the set of strictly positive real numbers.

in R|C|+|S|

++

11

be optimal for the problem with unknown client types. This alteration yields the following
problem:

(cid:88)

iâˆˆB,sâˆˆS

maximizeÏ€âˆˆÎ N

Ï(i)Î¾Ï€(i, s)(A(i, s) âˆ’ pâˆ—(s)) ,

(7)

However, since pâˆ—(s) may not be the correct dual variables (they were computed from an
optimization problem where client types are known), solving the preceding problem will in
general will lead to capacity violations (this is also related to Remark 2 above). In fact, if
indeed there is an optimal solution to the preceding problem that ensures that the capacities
are not exceeded, and also ensures that the servers that were utilized to their full capacity
in the solution to problem (4) are fully utilized in (7) as well, then (a) pâˆ—(s) would indeed be
the optimal dual variables in the original problem (2), and (b) this solution will be optimal
in the original problem (2).8

Our main result develops a regret-optimal algorithm for the preceding problem (7), where
by regret-optimal here we mean that it achieves the diï¬€erence in the optimal value of this
problem and the same problem but with known types up to the leading order term (asymp-
totically in N). The algorithm further ensures that capacities are not violated, and that the
servers that were fully utilized in the solution to problem (4) remain fully utilized. These
two properties imply that the algorithm is regret-optimal in the original problem (2). The
problem of developing such an algorithm appears to closely resemble a multi-armed bandit
problem [2], with the main departure being the need to satisfy these capacity utilization
requirements.

6 A regret-optimal algorithm

In this section we present a regret-optimal algorithm to solve (2). We begin the section
with an example to illustrate the main diï¬ƒculties our algorithm addresses. For convenience,
we deï¬ne the absolute regret of a policy to the be the expected total loss in payoï¬€ for one
client over N jobs, relative to the payoï¬€ achievable if the client type was known. (Hence,
the absolute regret is simply N times the regret).

6.1 Illustrative example

We study a simple example from four perspectives: known or unknown client types, with
and without capacity constraints. In the example we study there are 3 client types, a, b and
c, bringing in jobs at rates Ï0(a) = Ï0(b) = Ï0(c) = 0.5. There are three server types 1, 2
and 3, whose eï¬€ective service rates are Â¯Âµ(1) = 0.7, Â¯Âµ(2) = 0.7 and Â¯Âµ(3) = 0.2. The matrix
of probability of rewards is shown in Figure 1.

We ï¬rst consider this model without capacity constraints on the servers [2]. The optimal
routing policy in this case if the client type is known is to route jobs from type a to server

8This is easy to see from the optimality conditions.

12

Figure 1: A matrix for an example with three client types, a, b, and c, and three server types
1, 2 and 3.

type 1, and the jobs from b and c to server type 2. As a consequence, even if the client type
is not known, an adaptive allocation policy need not invest any eï¬€ort to distinguish between
client types b and c: both of them have a common optimal server type, namely type 2.

But when the client type is unknown, the optimal algorithm does need to distinguish
between client type a and the other two types, since their optimal servers are diï¬€erent. But
with server 2, the probabilities of reward are the same for all the three types, and hence it
cannot help in making this distinction. Hence any optimal policy must send some jobs to
either server 1 or server 3 in order to distinguish the client types, and thus in the event that
the client is of type b or type c, some loss relative to the case of known types is unavoidable.
This aspect of the example illustrates that there may be â€œdiï¬ƒcultâ€ (yet necessary) type
distinction requirements, that force the algorithm to incur regret over the short-term in
order to maximize long-run average payoï¬€.

Note that an â„¦(1) absolute regret is unavoidable whenever we donâ€™t have a single server
type that is optimal for all client types, since for any policy, there will be at least one client
type such that an expected â„¦(1) jobs (out of N ) for the client are sent to a suboptimal server
type. However, in our example, the diï¬ƒculties in distinguishing the class {b, c} from a are
more serious. In particular, it turns out that absolute regret of â„¦(log N ) is unavoidable. To
get a sense of why this is true, imagine a policy that initially sends a small number k of
jobs (leading to Î˜(k) absolute regret) to server type 1 and/or 3, and based on the realized
payoï¬€s, estimates (with conï¬dence 1 âˆ’ exp(âˆ’O(k))) that the client type is in {b, c}. Based
on this estimate, the policy can choose to send all future jobs from that client to server type
2. However, this means that there will be no further learning about the client type, and
the expected contribution to absolute regret is about N times the probability that the true
client type is actually a, i.e., N exp(âˆ’O(k)). Combining, we see the total absolute regret is at
least Î˜(k) + N exp(âˆ’Î˜(k)) â‰¥ Î˜(log N ), where k = Î˜(log N ) is needed to achieve Î˜(log N )
absolute regret.

Now we consider the model with capacity constraints at the servers, as in Figure 1. It is
straightforward to check that the optimal routing policy with known types is as follows: all

13

0.5     aClientsServers0.7 ğœ‡0.70.2ğœŒ00.80.60.100.60.200.60.50.5     b0.5     cthe a jobs are sent to server type 1; b jobs are split between server types 2 and 3 as [0.4+x, 0];
and c jobs are split between server types 2 and 3 as [0.3 âˆ’ x, 0.2], for any x âˆˆ [0, 0.1]. The
dual optimal prices for the server types are unique, and they are: pâˆ—(1) = 0, pâˆ—(2) = 0.6 and
pâˆ—(3) = 0.5.9

Note that now server type 2, which is optimal for client types b and c in the unconstrained
problem, does not have adequate capacity to serve all jobs arriving to it. Therefore some of
the jobs of client type c have to be served by server 3 to avoid violating capacity constraints.
As a result, with unknown client types and the speciï¬ed capacity constraints, the optimal
policy must invest eï¬€ort in distinguishing between the client types b and c â€” in contrast to
the problem without capacity constraints.

We conclude by showing that even introducing the externality prices is not enough to
prevent capacity violations. In particular, suppose we account for the externality imposed by
capacity constraints by using the externality-adjusted payoï¬€s A(i, s) âˆ’ pâˆ—(s), cf. problem 7.
Next, we employ a â€œblack-boxâ€ implementation of any optimal multiarmed bandit algorithm
for the resulting learning problem (such as the one proposed in [1]) on a client-by-client basis,
without any modiï¬cation to accommodate capacity constraints. Such an algorithm would
never use server type 3 (since this server is weakly dominated by server types 1 and 2), and
thus will never distinguish client types b and c. This will lead to a loss in the rate of payoï¬€
accumulation, as well as possible violation of the capacity of server 2. This phenomenon is
general, cf. Remark 2, and demonstrates why simply introducing the externality-adjusted
payoï¬€s is insuï¬ƒcient to solve the general capacity constrained problem (2).

6.2 Guess, conï¬rm, exploit

We now generalize the insights from the preceding example to motivate and describe our
approach. Our central object of study is a policy Ï€âˆ— that focuses on regret minimization with
respect to the externality-adjusted payoï¬€s of each client. Our algorithm design is character-
ized by three â€œphasesâ€: When a new client arrives, the policy ï¬rst enters a guessing phase,
used to form an initial conjecture about the client type; this is followed by a conï¬rmation
phase, used to conï¬rm (or reject) the initial guess â€” and in particular, as the preceding ex-
ample suggests is essential, to distinguish from other client types; and ï¬nally, an exploitation
phase, focused on payoï¬€ maximization for the conï¬rmed client type, while ensuring capacity
is not violated.
We describe each of these phases next; a formal deï¬nition of the policy Ï€âˆ— comes in
the following subsection. Recall that S(i) is the set of server types that maximize the
externality-adjusted payoï¬€ A(i, s) âˆ’ pâˆ—(s) for client type i.

1. Phase 1: Guessing. This is a short phase in which we try to form a quick guess of
the client type. The server types are chosen in a round-robin fashion (so that all types can

9For a moment suppose type a is removed from the example. The need to make this type of distinction
between b and c for capacity reasons only leads to an â„¦(1) regret, since one only needs to diï¬€erentiate
between types b and c enough to in eï¬€ect achieve the desired routing. If the estimated type is c and jobs are
sent to server type 3, then the estimate continues to get reï¬ned. On the other hand if the server type 2 is
used, there is no accumulation of regret anyway, since type 2 is optimal for both b and c.

14

âˆš
be distinguished from each other) for a ï¬xed O(
log N ) number of jobs so that at the end
âˆš
of this phase, the type of the client is guessed to be some i, and the probability of error is
exp(âˆ’â„¦(
log N )).

2. Phase 2: Conï¬rmation. Suppose that we have guessed the client type is i. The
second phase seeks to conï¬rm this guess. In particular, the algorithm must compare i to
each other type i(cid:48). There are two key cases to consider here, as we now discuss.

â€¢ Case 1 (An easy type pair): A(i, s) (cid:54)= A(i(cid:48), s) for at least one s âˆˆ S(i). In this case, the
server s can be used to distinguish between types i and i(cid:48), without incurring any regret
if the true type is conï¬rmed to be i. In the example above, the server 1 can be used to
distinguish between client type a and client types b and c, without incurring regret if
the true client type is a.
To cover this case the algorithm directs Î˜(log N ) jobs (in expectation) uniformly to all
the servers in S(i), based on which we either conï¬rm once and for all that the type is
i and move to the exploitation phase, or we learn that we made a mistake and go back
to the guessing phase.

â€¢ Case 2 (A diï¬ƒcult type pair): A(i, s) = A(i(cid:48), s) for all s âˆˆ S(i) and S(i) âˆ© S(i(cid:48)) = Ï†.
This is the most challenging case to address. We refer to a pair (i, i(cid:48)) such that the
conditions of this case hold as a diï¬ƒcult type pair. In general, if none of the server types
in S(i) allow us to distinguish between i and i(cid:48), and all the servers in S(i) are strictly
suboptimal for i(cid:48), then any policy that achieves small regret must send some jobs to
other servers who allow us to make this distinction. This process must incur a loss in
the event that the true client type is i. In the example above (with externality-adjusted
payoï¬€s), the pair (b, c) is an example of a diï¬ƒcult type pair.
In this case we need to send some jobs to other servers that allow i to be distinguished
from i(cid:48). Note that in choosing such servers, there are two objectives to consider: mini-
mizing the regret incurred from choosing a given server (based on the guessed type i),
and maximizing the rate at which that server helps us distinguish i from i(cid:48).
Recall that U (i) is the optimal externality-adjusted payoï¬€ of user i (cf. (5)). The loss
relative to this optimum for each server s is U (i) âˆ’ A(i, s) âˆ’ pâˆ—(s). On the other hand,
for any server s that can distinguish between i and i(cid:48), the expected number of jobs
taken to distinguish them with probability of error less than 1/N is (log N )/I(i, i(cid:48)|s),
where I(i, i(cid:48)|s) is the Kullback-Liebler (KL) divergence between the reward distribution
Bernoulli(A(i, s)) and the reward distribution Bernoulli(A(i(cid:48), s)).10 Thus the optimal
server is the one for which the following relative loss is minimized:

U (i) âˆ’ [A(i, s) âˆ’ pâˆ—(s)]

I(i, i(cid:48)|s)

.

In our algorithm design, we simultaneously compare i against all other i(cid:48) for which
(i, i(cid:48)) is a diï¬ƒcult type pair. This requires eï¬ƒciently choosing (a distribution over)
10The KL divergence between a Bernoulli(A(i,s)) and a Bernoulli(A(iâ€™,s)) distribution is deï¬ned as

I(i, i(cid:48)|s) = A(i, s) log A(i,s)

A(i(cid:48),s) + (1 âˆ’ A(i, s) log 1âˆ’A(i,s)
1âˆ’A(i(cid:48),s)

15

suboptimal servers, and a generalization of the preceding relative loss metric in the
case of multiple diï¬ƒcult type pairs.

â€¢ Case 3 (No need to distinguish): A(i, s) = A(i(cid:48), s) for all s âˆˆ S(i) and S(i)âˆ©S(i(cid:48)) (cid:54)= Ï†.
In this case, no server in S(i) can be used to distinguish i from i(cid:48), but S(i) has nonempty
intersection with S(i(cid:48)). It can be easily shown that this implies that S(i) âŠ† S(i(cid:48)):
if
s âˆˆ S(i) âˆ© S(i(cid:48)) and A(i, s) = A(i(cid:48), s), then is immediately seen that i and i(cid:48) have the
same optimal externality-adjusted payoï¬€ for s and hence for every other server type
in S(i). But then every server in S(i) must also be optimal for i(cid:48). In this case, the
algorithm need not invest jobs in trying to distinguish i from i(cid:48): even if the true type
happened to be i(cid:48), no regret is incurred by supposing that the true type is i. Note that
in principle, if the true type is i(cid:48) but the algorithm believes it to be i, it may not allocate
jobs to servers to manage the capacity constraint eï¬€ectively; e.g., in the example above,
S(b) âŠ‚ S(c), so if the algorithm guessed b but the true type were c, it would mistakenly
fail to send some jobs to server 3. We address this issue by careful adjustment of the
routing matrix in the exploitation phase, to ensure that any this issue does not result
in capacity violations (or loss of payoï¬€).

3. Phase 3: Exploitation. In this phase, the jobs are directed to the optimal server
types for the conï¬rmed client type i according to a particular routing matrix yâˆ—. This matrix
is carefully constructed to ensure that the capacity constraints are not violated overall. The
idea is to construct yâˆ— to closely resemble an optimal solution xâˆ— to the problem with known
types (cf. (4)). The routing matrix yâˆ— needs two key properties: ï¬rst, it should correct for
errors relative to xâˆ— that occur during routing in the guessing and conï¬rmation phases; and
second, it should account for the fact that the conï¬rmed type may be incorrect with some
probability (e.g., in Case 1 of the conï¬rmation phase, described above). Also, yâˆ— should
share the support of xâˆ—. We show in Proposition 8.4 that such a yâˆ— can indeed be chosen
under the generalized imbalance condition.

We refer to a type i as a diï¬ƒcult type if there is at least one i(cid:48) such that (i, i(cid:48)) is a diï¬ƒcult
type pair. The presence of diï¬ƒcult types makes the optimal regret scale as Î˜(log N/N ) [1].
This is because for any diï¬ƒcult type i, some eï¬€ort must be spent distinguishing i from all
i(cid:48) such that (i, i(cid:48)) is a diï¬ƒcult type pair, cf. Section 6.1. On the other hand if there is no
diï¬ƒcult type, then the optimal regret scaling is O(fN /N ) for any fN = Ï‰(1) (this follows
immediately from the proof of our main theorem). The reason is that only O(fN ) jobs from
a client of type i need to be sent to servers not in S(i).

Nominally, we might expect that generically for any values of the A matrix, diï¬ƒcult
type pairs do not exist: the deï¬nition requires exact equality in payoï¬€s. On the other
hand, this extreme interpretation is somewhat misleading, and an artifact of considering
the absolute limit where N â†’ âˆ. For example, if A(i, s) = 0.5 and A(i(cid:48), s) = 0.6, it
would take approximately 1/(0.1)2 = 100 jobs to distinguish i and i(cid:48) using s, which may
be comparable to (or more likely larger than) practical values of N ; e.g,. in a platform like
Upwork, clients may not bring more than a few jobs per month. Therefore s is practically
unable to distinguish between i and i(cid:48). For this reason, we consider a full understanding of

16

the general setting with diï¬ƒcult types to be the more relevant scenario to study. Formally,
we consider the case where at least one diï¬ƒcult type pair exists, so that there is a tradeoï¬€
between myopic payoï¬€s and learning.
6.3 Formal deï¬nition of the policy Ï€âˆ—
In this section we provide a formal deï¬nition of the policy Ï€âˆ—, based on the discussion above.
We require a few additional pieces of notation. For each client type i, let Cd(i) be the set of
types i(cid:48) such that (i, i(cid:48)) is a diï¬ƒcult type pair; and let C(cid:48) be the set of diï¬ƒcult types. Recall
these are the client types described in Case 2 of the discussion of the conï¬rmation phase
above.
Next, for client type i, let Ce(i) be the set of types that can be distinguished from i using
a server type in S(i):

Ce(i) = {i(cid:48) âˆˆ C : âˆƒs âˆˆ S(i) s.t. A(i, s) (cid:54)= A(i(cid:48), s)}.

(8)
The subscript â€œeâ€ refers to the fact that these are types i(cid:48) such that it is easy to distinguish
i from i(cid:48). Recall that these are the client types described in Case 1 of discussion of the
conï¬rmation phase above.
Next, let S(i) = S \S(i) be the set of all server types that are sub-optimal for client type
i. Finally, note that since each client type is distinguishable by some server type, there exist

integers Ks â‰¥ 0 for each s âˆˆ S such that(cid:88)
for any i, i(cid:48) âˆˆ C. Let Ïˆ = mini,i(cid:48)âˆˆC |(cid:80)
Let p be the empirical average reward per round, and let iâˆ— âˆˆ arg min|pâˆ’(cid:80)

The policy Ï€âˆ— is formally deï¬ned as follows.
âˆš
1. Phase 1: Guessing. Fix an arbitrary order of the server types. For 2

rounds, in each round, allot the client to server s for Ks number of times in the ï¬xed order.
sâˆˆS KsA(i, s)|.11
2. Phase 2: Conï¬rmation. We separate this phase into two subphases. If the guessed
type iâˆ— is a diï¬ƒcult type, we try to distinguish iâˆ— from all types in Cd(iâˆ—); this is called
conï¬rmation phase A. Next, if there are any remaining types i(cid:48) âˆˆ Ce(iâˆ—), we try to distinguish
iâˆ— from them; this is called conï¬rmation phase B.

sâˆˆS Ks(A(i, s) âˆ’ A(i(cid:48), s))|.

log N ((cid:80)

Ïˆ2

KsA(i, s) (cid:54)=

(cid:88)

sâˆˆS

KsA(i(cid:48), s)

s Ks)2

sâˆˆS

(a) Phase A: Diï¬ƒcult types. This phase is only executed for diï¬ƒcult types; if Cd(iâˆ—) is
empty, the algorithm directly proceeds to conï¬rmation phase B. Let QN = N log N . Further,
let

(cid:80)

sâˆˆS(iâˆ—) Î±s

(cid:18)
(cid:80)
U (iâˆ—) âˆ’ [A(iâˆ—, s) âˆ’ pâˆ—(s)]
sâˆˆS(iâˆ—) Î±sI(iâˆ—, i(cid:48)|s)

(cid:19)

.

Î±âˆ— âˆˆ arg min
Î±âˆˆâˆ†(S(iâˆ—))

11All the results will still hold if

max
i(cid:48)âˆˆCd(iâˆ—)
âˆš

log N here is replaced by any f (N ) = â„¦(log log N ) âˆ© o(log N ).

17

Let the time in this phase be labeled as n = 1, 2,Â·Â·Â· . At each time n, a server in S(iâˆ—) is
chosen according to the distribution Î±âˆ—. Let the server type chosen at time n be sn and the
outcome be Xn. For any i âˆˆ C and s âˆˆ S, let p(X, i, s) = A(i, s)1{X=1} + (1âˆ’ A(i, s))1{X=0}.
Let

n(cid:89)

t=1

Î›n(i, i(cid:48)) =

p(Xt, i, st)
p(Xt, i(cid:48), st)

,

i.e., the likelihood ratio of the observations under type i and i(cid:48). Finally let Î›n(i) =
(i) = mini(cid:48)âˆˆCd(i) Î›n(i, i(cid:48)). The conï¬rmation phase A continues
mini(cid:48)âˆˆC Î›n(i, i(cid:48)), and let Î›
until one of the following conditions is satisï¬ed:
(iâˆ—) â‰¥ QN , in which case we say that iâˆ— is conï¬rmed and move on to the ex-

Cd(i)
n

Cd(iâˆ—)
i. Î›
n
ploitation phase.
ii. Î›n â‰¤ 1

QN

the guessing phase.

, in which case we declare the conï¬rmation phase a failure and go back to

(b) Phase B: Easy types. Let iâˆ— be the conï¬rmed client type and let the time in this
phase be labelled as n = 1, 2,Â·Â·Â· . Then at each stage n, choose a server in S(iâˆ—) uniformly
at random. Keep track of the likelihood ratio

Î›Ce(iâˆ—)

n

(iâˆ—) = min
i(cid:48)âˆˆCe(iâˆ—)

Î›n(iâˆ—, i(cid:48)).

Then the conï¬rmation phase B continues until either of the two conditions hold:

Ce(iâˆ—)
i. Î›
n

(iâˆ—) > QN , in which case we move on to the exploitation phase.
Ce(iâˆ—)
ii. If Î›
n

, in which case we declare the conï¬rmation phase a failure and go

(iâˆ—) â‰¤ 1

back to the guessing phase.

QN

3. Phase 3: Exploitation. For each job, choose a server in S(iâˆ—) with probability

yâˆ—(iâˆ—, s), where yâˆ— is a speciï¬ed routing matrix (cf. Proposition 8.4 in the Appendix).

6.4 Main result

We conclude by presenting our main theorem analyzing the performance of the policy de-
scribed above.

We begin with a relatively straightforward result that provides some intuition. When a
single client brings a large number of jobs, we expect that this eases the burden of learning;
and in fact asymptotically as N â†’ âˆ, allows for the same rate of payoï¬€ accumulation as if the
type of a client is known from the start. In terms of problem 2, we expect limNâ†’âˆ ÎN = D,
where recall that

D =

x âˆˆ R|C|Ã—|S| : x(i, s) â‰¥ 0;

x(i, s) = 1

,

(9)

(cid:26)

(cid:27)

(cid:88)

sâˆˆS

is the set of achievable routing matrices when client types are known. Indeed, under the mild
requirement that no two rows of the expected payoï¬€ matrix A are identical, we establish that

18

limNâ†’âˆ ÎN = D; see Proposition 8.7 in the Appendix for details, where we also show how a
simple family of naive â€œexplore then exploitâ€ policies achieves the optimal performance with
known types (V âˆ—, cf. problem (4)) asymptotically as N â†’ âˆ.

The problem with these simple, naive policies is that they incur high regret, precisely
because they donâ€™t account for the cases described in both our example and the description
of the policy Ï€âˆ—. To that end, the following theorem is our main result: it shows the policy
Ï€âˆ— described above not only achieves a payoï¬€ of V âˆ— in the limit as N â†’ âˆ, it also has
optimal regret to leading order in N .

Theorem 6.1. Suppose that the generalized imbalance condition holds (Deï¬nition 1). Sup-
pose also that no two rows of A are identical, and that at least one diï¬ƒcult type pair (deï¬ned
in Section 6.2) exists.
there is a constant C = C(Ï0, Â¯Âµ, A) âˆˆ (0,âˆ) such that we have:

Let W N (Ï€âˆ—) denote the rate of payoï¬€ accumulation of policy Ï€âˆ— described below. Then

V âˆ— âˆ’ W N (Ï€âˆ—) = C log N/N + o(log N/N ) .

Moreover, policy Ï€âˆ— achieves the optimal regret to leading order, i.e., we have

V âˆ— âˆ’ W N = C log N/N + o(log N/N )

or equivalently

W N âˆ’ W N (Ï€âˆ—) = o(log N/N ) .

We precisely characterize the constant C in the Appendix (see Propositions 8.1 and 8.6).

Proof sketch. The critical ingredient in the proof of the theorem is the following relaxed opti-
mization problem. In this problem there are no capacity constraints, but capacity violations
are charged with prices pâˆ— from the optimization problem with known client types.

W N

pâˆ— = max
Î¾âˆˆÎN

(cid:88)
âˆ’(cid:88)

iâˆˆC

sâˆˆS

(cid:88)
(cid:88)

sâˆˆS

iâˆˆC

Ï0(i)

pâˆ—(s)[

Î¾(i, s)A(i, s)

Ï0(i)Î¾(i, s) âˆ’ Â¯Âµ(s)].

(10)

Now subject to there being at least one pair of diï¬ƒcult client types, there is an upper bound
for the performance of any policy in this problem, expressed relative to V âˆ— [1]:

V âˆ— âˆ’ W N

pâˆ— â‰¥ C log N/N + o(log N/N ),

where C > 0 is precisely the constant appearing in the theorem. By a standard duality
pâˆ— â‰¥ W N , and hence this bound holds for W N as well (see
argument, we know that W N
pâˆ— (Ï€âˆ—) denote the value attained by the policy Ï€âˆ— in this problem.
Proposition 8.1). Let W N
Then there are two key steps in the proof.

19

1. First, we show that our policy Ï€âˆ— achieves near optimal performance in problem (10),

i.e.,

V âˆ— âˆ’ W N
This is shown in Proposition 8.2.

pâˆ— (Ï€âˆ—) = C log N/N + o(log N/N ).

To gain some intuition for this result, ï¬rst note that the diï¬€erence in values V âˆ— and W N
pâˆ—

is the diï¬€erence between: (cid:88)

Ï0(i) max

sâˆˆS [A(i, s) âˆ’ pâˆ—(s)], and
(cid:88)

Î¾(i, s)[A(i, s) âˆ’ pâˆ—(s)].

Ï0(i)

(cid:88)

iâˆˆC

iâˆˆC

max
Î¾âˆˆÎN

sâˆˆS

(11)

(12)

Now an optimal policy that solves (11) has to try to choose the optimal server type in
S(i) = arg maxsâˆˆS[A(i, s) âˆ’ pâˆ—(s)] for each client type i, but without knowing what the type
is, which is exactly problem (7): the unconstrained MAB problem discussed in the example
with externality adjusted payoï¬€s.

As we have discussed in the example, in order to ensure an absolute regret of O(log N )
relative to the problem where the client types are known, for each diï¬ƒcult type i, one needs
to distinguish that type from all the other types that form a diï¬ƒcult pair with this type
with a conï¬dence of at least 1 âˆ’ 1/N . Further, there is an optimal â€œconï¬rmationâ€ policy
for making this distinction that appropriately routes the jobs to the suboptimal servers
S(i). This policy strikes the right balance between the average number of jobs required
to make these distinctions, and the average per-job regret incurred with respect to U (i).
This resulting optimal regret is Ci log N for each type i, where Ci > 0 can be exactly
characterized, and on the event that the true type is i, this regret is unavoidable, which
results in the O(log N ) regret overall. Now the challenge for any policy that tries to achieve
this bound is to achieve these type-dependent minimal regrets without a priori knowing the
true type. This is where the short guessing phase of length o(log N ) helps. After we form
an initial guess of the underlying type, the optimal conï¬rmation policy for the guessed type
can be used to conï¬rm that type later in the conï¬rmation phase, thus ensuring the optimal
regret up to the leading order term.

2. In the next part of the proof, we show that by using the generalized imbalance con-
dition, for a large enough N , we can design a routing matrix yâˆ— (that depends on N ) to be
used in the exploitation phase of the policy Ï€âˆ—, with the following two properties:

iâˆˆC Ï(i)Î¾Ï€âˆ—(i, s) âˆ’ Â¯Âµ(s) = 0 for any server s such that pâˆ—(s) > 0, and,
iâˆˆC Ï(i)Î¾Ï€âˆ—(i, s) âˆ’ Â¯Âµ(s) â‰¤ 0 for any other server.

This means that by this choice of yâˆ—, the algorithm ensures that capacity constraints are
not violated, and that the servers that were fully utilized in the solution to problem (4), i.e.,
under the routing matrix xâˆ—, remain fully utilized. This is shown in Proposition 8.4.

20

(a) (cid:80)
(b) (cid:80)

The key point here is that at the end of the conï¬rmation phase of the policy, the type
of the client is learned with a conï¬dence of at least (1 âˆ’ o(1)), and this fact coupled with
the generalized imbalance condition is suï¬ƒcient to ensure an appropriate choice of yâˆ— will
correct (almost) all the deviations from xâˆ—â€™s capacity utilizations that may have happened
in the guessing and the conï¬rmation phase, and also the deviations that will happen in the
exploitation phase owing to the fact that the type is not learned perfectly.

One can see this in our example. Suppose that our policy initially guessed that the client
type is b, and further it has distinguished it from a in the conï¬rmation phase. At this point,
since the b and c have a common optimal server type 2, the policy will not try to distinguish
them any more (see Case 3 in the informal description of our algorithm) and enter the
exploitation phase, directing all remaining jobs to seller 2. But since there is a (vanishing)
chance that the true type was actually c, which is supposed to be routed to seller 3 as well
in the optimal policy, we make up for the possible under-utilization of seller 3 by sending a
larger fraction of the jobs to seller 3 than required by the optimal policy xâˆ— in the case that
we actually conï¬rm that the client type is c. The result shows that such corrections can
always we done for a large enough N , assuming that the generalized imbalance condition
holds.
These two results together ensure that the policy Ï€âˆ— is feasible in problem (2), and further,

the rate of accumulation of payoï¬€(cid:88)

(cid:88)

is near-optimal (since this is precisely W N
result.

Ï0(i)

Î¾Ï€âˆ—(i, s)A(i, s)

iâˆˆC

sâˆˆS
pâˆ— (Ï€âˆ—)). The combination of these facts gives us the

7 Conclusion

As noted in the introduction, this work suggests a fruitful algorithmic approach with po-
tentially very wide-ranging application, from retail to online matching markets. There are
certainly several generalizations of the model that would enrich the class of applications
where our analysis applies. Two in particular are important open directions: (1) generaliz-
ing the model of types beyond the ï¬nite type model considered here (e.g., clients and servers
may be characterized by features in a vector-valued space, with compatibility determined
by the inner product between feature vectors); and (2) generalizing the model to allow two-
sided uncertainty (i.e., where the types of newly arriving servers must also be simultaneously
learned). Our conjecture is that the same combination of externality pricing with an al-
gorithmic design that prevents capacity violations should be applicable even in these more
general settings, with an appropriate modeling framework.

Finally, we note two further directions that are likely to require substantial additional
technical analysis beyond this paper. First, recall that we assumed the expected surplus
from a match between a client type and server type (i.e., the A matrix) is known to the

21

platform. This reï¬‚ects the ï¬rst order concern of most platforms, where aggregate knowledge
is available, but learning individual user types quickly is challenging. It may be of interest
to study how A can be eï¬ƒciently learned by the platform. Our problem appears to be a
discrete analog of the problem of learning a mixture of (multidimensional) Gaussians, which
can be achieved using polynomial-sized data and polynomial computation [36].12

Second, our model does not contain any analysis of strategic behavior by clients or
servers. A ï¬rst strategic model might consider the fact that clients or servers are less likely
to return to the platform after several bad experiences; this would dramatically alter the
multiarmed bandit model, and force the algorithm to be more conservative to retain users.
More generally, users may consider strategic manipulation to, e.g., improve the matches
made on their behalf by the algorithm. Both the modeling and analysis of these strategic
behaviors remain important challenges for future work.

References

[1] Rajeev Agrawal, Demosthenis Teneketzis, and Venkatachalam Anantharam. 1989a.
Asymptotically eï¬ƒcient adaptive allocation schemes for controlled iid processes: ï¬nite
parameter space. Automatic Control, IEEE Transactions on 34, 3 (1989), 258â€“267.

[2] Rajeev Agrawal, Demosthenis Teneketzis, and Venkatachalam Anantharam. 1989b.
Asymptotically eï¬ƒcient adaptive allocation schemes for controlled Markov chains: Fi-
nite parameter space. Automatic Control, IEEE Transactions on 34, 12 (1989), 1249â€“
1259.

[3] Shipra Agrawal and Nikhil R Devanur. 2014. Bandits with concave rewards and convex
knapsacks. In Proceedings of the ï¬fteenth ACM conference on Economics and computa-
tion. ACM, 989â€“1006.

[4] Shipra Agrawal and Nikhil R Devanur. 2015. Linear Contextual Bandits with Global

Constraints and Objective. arXiv preprint arXiv:1507.06738 (2015).

[5] Shipra Agrawal, Nikhil R Devanur, and Lihong Li. 2015. Contextual Bandits with

Global Constraints and Objective. arXiv preprint arXiv:1506.03374 (2015).

[6] Shipra Agrawal and Navin Goyal. 2011. Analysis of Thompson sampling for the multi-

armed bandit problem. arXiv preprint arXiv:1111.1797 (2011).

[7] Mohammad Akbarpour, Shengwu Li, and Shayan Oveis Gharan. 2014. Dynamic match-

ing market design. Available at SSRN 2394319 (2014).

12If a ï¬xed number Ns of jobs from each client are sent to each server type s, then the resultant joint
distribution of total payoï¬€ realized from each server type s is a mixture (indexed by i) over a product
measure over binomials (Binomial(Ns, A(i, s)))sâˆˆS . This should already allow for learning A eï¬ƒciently
unless the discrete case is very diï¬€erent from the continuous analog (this would be a mixture of spherical
Gaussians, e.g., see Dasgupta [24]).

22

[8] Ross Anderson, Itai Ashlagi, David Gamarnik, and Yash Kanoria. 2015. A dynamic
model of barter exchange. In Proceedings of the Twenty-Sixth Annual ACM-SIAM Sym-
posium on Discrete Algorithms. SIAM, 1925â€“1933.

[9] Baris Ata, Sunil Kumar, and others. 2005. Heavy traï¬ƒc analysis of open processing net-
works with complete resource pooling: asymptotic optimality of discrete review policies.
The Annals of Applied Probability 15, 1A (2005), 331â€“391.

[10] J.-Y. Audibert and R. Munos. 2011. Introduction to Bandits: Algorithms and Theory.

In ICML.

[11] Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. 2002. Finite-time analysis of the

multiarmed bandit problem. Machine learning 47, 2-3 (2002), 235â€“256.

[12] Moshe Babaioï¬€, Shaddin Dughmi, Robert Kleinberg, and Aleksandrs Slivkins. 2015.
Dynamic pricing with limited supply. ACM Transactions on Economics and Computa-
tion 3, 1 (2015), 4.

[13] Mariagiovanna Baccara, SangMok Lee, and Leeat Yariv. 2015. Optimal dynamic match-

ing. Available at SSRN 2641670 (2015).

[14] Ashwinkumar Badanidiyuru, Robert Kleinberg, and Yaron Singer. 2012. Learning on
a budget: posted price mechanisms for online procurement. In Proceedings of the 13th
ACM Conference on Electronic Commerce. ACM, 128â€“145.

[15] Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins. 2013. Bandits
with knapsacks. In Foundations of Computer Science (FOCS), 2013 IEEE 54th Annual
Symposium on. IEEE, 207â€“216.

[16] Ashwinkumar Badanidiyuru, John Langford, and Aleksandrs Slivkins. 2014. Resourceful
Contextual Bandits. In Proceedings of The 27th Conference on Learning Theory. 1109â€“
1134.

[17] Omar Besbes and Assaf Zeevi. 2009. Dynamic pricing without knowing the demand
function: Risk bounds and near-optimal algorithms. Operations Research 57, 6 (2009),
1407â€“1420.

[18] Omar Besbes and Assaf Zeevi. 2012. Blind network revenue management. Operations

research 60, 6 (2012), 1537â€“1550.

[19] SÂ´ebastien Bubeck and Nicolo Cesa-Bianchi. 2012. Regret Analysis of Stochastic and

Nonstochastic Multi-armed Bandit Problems. Machine Learning 5, 1 (2012), 1â€“122.

[20] Wei Chu, Lihong Li, Lev Reyzin, and Robert E Schapire. 2011. Contextual bandits
with linear payoï¬€ functions. In International Conference on Artiï¬cial Intelligence and
Statistics. 208â€“214.

23

[21] Jim G Dai. 1995. On positive Harris recurrence of multiclass queueing networks: a
uniï¬ed approach via ï¬‚uid limit models. The Annals of Applied Probability (1995), 49â€“
77.

[22] Ettore Damiano and Ricky Lam. 2005. Stability in dynamic matching markets. Games

and Economic Behavior 52, 1 (2005), 34â€“53.

[23] Sanmay Das and Emir Kamenica. 2005. Two-sided bandits and the dating market. In
Proceedings of the 19th international joint conference on Artiï¬cial intelligence. Morgan
Kaufmann Publishers Inc., 947â€“952.

[24] Sanjoy Dasgupta. 1999. Learning mixtures of Gaussians. In Foundations of Computer

Science, 1999. 40th Annual Symposium on. IEEE, 634â€“644.

[25] Daniel Fershtman and Alessandro Pavan. 2015. Dynamic matching: experimentation

and cross subsidization. Technical Report. Citeseer.

[26] John Gittins, Kevin Glazebrook, and Richard Weber. 2011. Multi-armed bandit alloca-

tion indices. John Wiley & Sons.

[27] Ming Hu and Yun Zhou. 2015. Dynamic Matching in a Two-Sided Market. Available

at SSRN (2015).

[28] Sangram V Kadam and Maciej H Kotowski. 2015. Multi-period Matching. Technical

Report. Harvard University, John F. Kennedy School of Government.

[29] Morimitsu Kurino. 2005. Credibility, eï¬ƒciency, and stability: A theory of dynamic

matching markets. (2005).

[30] Tze Leung Lai and Herbert Robbins. 1985. Asymptotically eï¬ƒcient adaptive allocation

rules. Advances in applied mathematics 6, 1 (1985), 4â€“22.

[31] John Langford and Tong Zhang. 2008. The epoch-greedy algorithm for multi-armed
bandits with side information. In Advances in neural information processing systems.
817â€“824.

[32] Constantinos Maglaras and Assaf Zeevi. 2003. Pricing and capacity sizing for systems
with shared resources: Approximate solutions and scaling relations. Management Sci-
ence 49, 8 (2003), 1018â€“1038.

[33] Constantinos Maglaras and Assaf Zeevi. 2005. Pricing and design of diï¬€erentiated ser-
vices: Approximate analysis and structural insights. Operations Research 53, 2 (2005),
242â€“262.

[34] Laurent Massoulie and Kuang Xu. 2016. On the Capacity of Information Processing

Systems. (2016). Unpublished.

24

[35] Aranyak Mehta. 2012. Online matching and ad allocation. Theoretical Computer Science

8, 4 (2012), 265â€“368.

[36] Ankur Moitra and Gregory Valiant. 2010. Settling the polynomial learnability of mix-
tures of gaussians. In Foundations of Computer Science (FOCS), 2010 51st Annual
IEEE Symposium on. IEEE, 93â€“102.

[37] Denis SaurÂ´e and Assaf Zeevi. 2013. Optimal dynamic assortment planning with demand

learning. Manufacturing & Service Operations Management 15, 3 (2013), 387â€“404.

[38] Lloyd S Shapley and Martin Shubik. 1971. The assignment game I: The core. Interna-

tional Journal of game theory 1, 1 (1971), 111â€“130.

[39] Adish Singla and Andreas Krause. 2013. Truthful incentives in crowdsourcing tasks us-
ing regret minimization mechanisms. In Proceedings of the 22nd international conference
on World Wide Web. International World Wide Web Conferences Steering Committee,
1167â€“1178.

[40] Zizhuo Wang, Shiming Deng, and Yinyu Ye. 2014. Close the gaps: A learning-while-
doing algorithm for single-product revenue management problems. Operations Research
62, 2 (2014), 318â€“331.

[41] Huasen Wu, R Srikant, Xin Liu, and Chong Jiang. 2015. Algorithms with logarithmic or
sublinear regret for constrained contextual bandits. In Advances in Neural Information
Processing Systems. 433â€“441.

8 Appendix

8.1 Proof of Theorem 6.1
We will ï¬rst show the following lower bound on the diï¬€erence between V âˆ— and W N
Proposition 8.1. Suppose that Pâˆ— is a singleton, and {pâˆ—(s)} are the unique optimal prices
in the matching problem with known client types. Then,

N

lim sup
Nâ†’âˆ

log N

(cid:80)

(cid:0)V âˆ— âˆ’ W N(cid:1)
(cid:18)
(cid:80)
U (i) âˆ’ [A(i, s) âˆ’ pâˆ—(s)]
sâˆˆS(i) Î±sI(i, i(cid:48)|s)

(cid:19)

.

sâˆˆS(i) Î±s

â‰¥(cid:88)

iâˆˆC(cid:48)

Ï0(i) min

Î±âˆˆâˆ†(S(i))

max
i(cid:48)âˆˆCd(i)

25

Proof. Consider the following relaxed problem:

W N

pâˆ— = max
Î¾âˆˆÎN

Ï(i)

Î¾(i, s)A(i, s)

pâˆ—(s)[

Ï(i)Î¾(i, s) âˆ’ Â¯Âµ(s)].

(13)

By a standard duality argument, we know that W N
problem is a solution to

pâˆ— â‰¥ W N . The optimal policy in this

maximizeÏ€âˆ—âˆˆÎ N

Ï(i)Î¾Ï€âˆ—(i, s)(A(i, s) âˆ’ pâˆ—(s)) .

(14)

(cid:88)
(cid:88)

sâˆˆS

iâˆˆC

(cid:88)
âˆ’(cid:88)

iâˆˆC

sâˆˆS

(cid:88)

iâˆˆB,sâˆˆS

Then from Theorem 3.1 in [1], we know that

(cid:0)V âˆ— âˆ’ W N
pâˆ—(cid:1)
(cid:18)
(cid:80)
U (i) âˆ’ [A(i, s) âˆ’ pâˆ—(s)]
sâˆˆS(i) Î±sI(i, i(cid:48)|s)
The result then follows from the fact that W N â‰¤ W N
pâˆ— .

â‰¥(cid:88)

lim sup
Nâ†’âˆ

Ï0(i) min

max
i(cid:48)âˆˆCd(i)

sâˆˆS(i) Î±s

(cid:80)

Î±âˆˆâˆ†(S(i))

log N

iâˆˆC(cid:48)

N

(cid:19)

.

and(cid:80)

Let W N

pâˆ— (Ï€âˆ—) be the value attained by the deï¬ned policy in optimization problem (10).
pâˆ— (Ï€âˆ—). Note that the

We will prove an upper bound on the diï¬€erence between V âˆ— and W N
diï¬€erence in these values of the two problems is the same as the diï¬€erence in:

(cid:88)

iâˆˆC

(cid:88)

sâˆˆS

Ï0(i)

Î¾Ï€âˆ—(i, s)(A(i, s) âˆ’ pâˆ—(s)),

iâˆˆC Ï0(i)U (i). Following is the result.

Proposition 8.2. Consider the policy Ï€âˆ— such that the routing matrix y used in the exploita-
tion phase satisï¬es y(i, .) âˆˆ âˆ†(S(i)). Then,

lim sup
Nâ†’âˆ

log N

N

(cid:80)

pâˆ— (Ï€âˆ—)(cid:1)

(cid:0)V âˆ— âˆ’ W N
(cid:18)
(cid:80)
U (i) âˆ’ [A(i, s) âˆ’ pâˆ—(s)]
sâˆˆS(i) Î±sI(i, i(cid:48)|s)

sâˆˆS(i) Î±s

(cid:19)

.

Ï0(i) min

Î±âˆˆâˆ†(S(i))

max
i(cid:48)âˆˆCd(i)

â‰¤(cid:88)

iâˆˆC(cid:48)

In order to prove this Lemma, we need the following result that follows from Theorem

4.1 in [1]. For two numbers a and b, let a âˆ§ b (cid:44) min(a, b).

26

Lemma 8.3. Let X1, X2,Â·Â·Â· be i.i.d. random variables where Xi is the outcome of choosing
a server type s âˆˆ S according to a distribution Î± âˆˆ âˆ†(S). Suppose i âˆˆ C and B âŠ‚ C are such
that

(cid:88)

(cid:20)

Î±sEi

p(X, i, s) log

p(X, i, s)
p(X, i(cid:48), s)

=

Î±sI(i, i(cid:48)|s) > 0

sâˆˆS

for each i(cid:48) âˆˆ B. Let

(cid:21)

(cid:88)

sâˆˆS

Î›B
n(i) = min
i(cid:48)âˆˆB

Î›n(i, i(cid:48)).

Then,

1.

2.

Ei[inf{n â‰¥ 0|Î›B

n(i) â‰¥ QN} âˆ§ N ]
log N

lim sup
Nâ†’âˆ

miniâˆˆB(cid:80)

â‰¤

1
sâˆˆS Î±sI(i, i(cid:48)|s)

,

Pi(cid:48)(Î›B

n(i) â‰¥ QN for some n â‰¤ N ) â‰¤ 1
QN

.

We are now ready to prove Proposition 8.2.

Proof. Let X be random variable denoting the true type of the client. Let R(i) denote the
expected absolute regret on the event {X = i}, deï¬ned as
sâˆˆS [A(i, s) âˆ’ pâˆ—(s)] âˆ’ N

R(i) = N max

(cid:88)

Î¾Ï€âˆ—(i, s).

sâˆˆS

We will refer to this quantity as just regret. We thus want to ï¬nd an upper bound on R(i).
First consider the event that the guessing phase guessed the type i correctly. By a standard
application of the Hoeï¬€ding bound, if iâˆ— is the guessed type at the end of the guessing phase,
then

P (iâˆ— (cid:54)= i) â‰¤ exp(âˆ’(cid:112)log N ).

Let Ai be the event that the guessing phase guessed the type i correctly. Then on the event
{X = i} âˆ© Ai, the conï¬rmation phase A fails to conï¬rm i and we go back to the guessing
phase if

Î›Cd(i)

n

(i) â‰¤ 1
QN

,

and conï¬rmation phase B fails to conï¬rm i and we go back to the guessing phase if

Î›Ce(i)

n

(i) â‰¤ 1
QN

,

Regret is incurred in the conï¬rmation phase at the expected rate of(cid:80)

the probability of each of which is bounded above by 1/QN by Lemma 8.3. Hence the
probability that either of the two phases fails to conï¬rm i is bounded above by 2/QN .
sâˆˆS(i) Î±s[A(i, s(i)) âˆ’
pâˆ—(s(i))] âˆ’ [A(i, s) âˆ’ pâˆ—(s)], and the expected duration of the conï¬rmation phase, regardless

27

of whether it conï¬rmed i or not, is bounded above by Ei[inf{n â‰¥ 0|Î›
event {X = i} âˆ© Ai, the expected regret is upper bounded by

Cd(i)
n

(i)]. Thus on the

O((cid:112)log N ) +

2
QN
Î±s[A(i, s(i)) âˆ’ pâˆ—(s(i))] âˆ’ [A(i, s) âˆ’ pâˆ—(s)]

(cid:19)

R(i)

(cid:18) (cid:88)

+

sâˆˆS(i)

Ei[inf{n â‰¥ 0|Î›Cd(i)

n

(i) â‰¥ QN} âˆ§ N ].

Now let Ac

i be the event that the guessing phase did not guess the type i correctly.
Consider the event {X = i} âˆ© Ac
i . Let iâˆ— be the type that was guessed instead. Then, in
case that i âˆˆ Cd(iâˆ—), from Lemma 8.3 we can see that the conï¬rmation phase fails to reject
iâˆ— with a probability at most 1/QN , in which case one incurs a regret of O(N ), otherwise we
return back to the guessing phase after an expected time not more than

Ei[inf{n â‰¥ 0|Î›n(iâˆ—, i) â‰¤ 1
QN

} âˆ§ N ],

In the case that i /âˆˆ Cd(iâˆ—), then there are two possibilities:

â€¢ One possibility is that i âˆˆ Ce(iâˆ—). Now if i is such that A(i, s) (cid:54)= A(iâˆ—, s) for some
s > 0, then the expected time spent in conï¬rmation phase A is

s âˆˆ S(iâˆ—) such that Î±âˆ—
at most

Ei[inf{n â‰¥ 0|Î›n(iâˆ—, i) â‰¤ 1
QN

} âˆ§ N ] = O(log N ).

by Lemma 8.3. Else if i is such that A(i, s) = A(iâˆ—, s) for all s âˆˆ S(iâˆ—) such that
Î±âˆ—
s > 0, then the expected time spent in conï¬rmation phase A is at most

Eiâˆ—[inf{n â‰¥ 0|Î›Cd(iâˆ—)

n

(iâˆ—) â‰¥ QN} âˆ§ N ] = O(log N ),

since in this case, in conï¬rmation phase A, the likelihood of events under i and iâˆ—
are identical. Thus in either case, the expected time spent in conï¬rmation phase A is
O(log N ). Also, in either case, the expected time spent in conï¬rmation phase B is at
most

Ei[inf{n â‰¥ 0|Î›n(iâˆ—, i) â‰¤ 1
QN

} âˆ§ N ] = O(log N ).

Further, both the conï¬rmation phase and the pre-exploitation phase fail to reject iâˆ—
with probability at most 1/QN , in which case you incur a regret of O(N ). Otherwise
you go back to the guessing phase.

â€¢ The other possibility is that i âˆˆ C \Ce(iâˆ—)âˆªCd(iâˆ—)âˆª{iâˆ—}. In this case, A(i, s) = A(iâˆ—, s)
for all s âˆˆ S(iâˆ—) and further S(iâˆ—) âˆ© S(i) (cid:54)= Ï† (Case 3 in the description of Ï€âˆ—) . This
implies that in fact S(iâˆ—) âŠ† S(i), and hence the optimal allocation policy for i does not
incur any regret if the guessed type is iâˆ—. Then either you reject iâˆ— in the conï¬rmation
phase and return to the guessing phase, or you are not able to reject iâˆ—, in which case

28

you donâ€™t incur any regret anymore since the optimal policy for iâˆ— is optimal for i as
well.
Now if i is such that A(i, s) (cid:54)= A(iâˆ—, s) for some s âˆˆ S(iâˆ—) such that Î±âˆ—
expected time spent in conï¬rmation phase A is at most

s > 0, then the

Ei[inf{n â‰¥ 0|Î›n(iâˆ—, i) â‰¤ 1
QN

} âˆ§ N ] = O(log N ).

Else if i is such that A(i, s) = A(iâˆ—, s) for all s âˆˆ S(iâˆ—) such that Î±âˆ—
expected time spent in conï¬rmation phase A is at most

s > 0, then the

Eiâˆ—[inf{n â‰¥ 0|Î›Cd(iâˆ—)

n

(iâˆ—) â‰¥ QN} âˆ§ N ] = O(log N ).

No regret is incurred in the conï¬rmation phase B (or exploitation phase) so its duration
does not matter. In either of the two cases, the conï¬rmation phases A and B together
fail to conï¬rm iâˆ— and we return to the guessing phase with a probability no more than
1/QN .

Thus overall, on the event {X = i} âˆ© Ac

i , the expected regret is bounded above by

Hence, on the event {X = i}, the total expected regret R(i) is bounded above as:

O((cid:112)log N ) + O(log N ) + R(i) +
R(i) â‰¤ O((cid:112)log N )
(cid:19)

1
QN

O(N )

(cid:18) (cid:88)

+

Î±s[A(i, s(i)) âˆ’ pâˆ—(s(i))] âˆ’ [A(i, s) âˆ’ pâˆ—(s)]

Ei[inf{n â‰¥ 0|Î›Cd(i)

n

sâˆˆS(i)

+

1
QN

(cid:18)
R(i) + exp(âˆ’(cid:112)log N )

(i) â‰¥ QN} âˆ§ N ]

(cid:19)

O(log N ) + R(i) +

O(N )

.

(15)

Now as a direct consequence of Lemma 8.3, we can ï¬rst see that the following holds in

conï¬rmation phase A:

Ei[inf{n â‰¥ 0|Î›

(i) â‰¥ QN} âˆ§ N ]

Cd(i)
n
log N

lim sup
Nâ†’âˆ

This is because Î±âˆ— is such that mini(cid:48)âˆˆCd(i)

â‰¤

mini(cid:48)âˆˆCd(i)

1
sâˆˆS(i) Î±âˆ—
sI(i, i(cid:48)|s) > 0, because if

sI(i, i(cid:48)|s)

.

(16)

(cid:80)
(cid:88)

sâˆˆS(i)

min
i(cid:48)âˆˆCd(i)

sâˆˆS(i) Î±âˆ—
sI(i, i(cid:48)|s) = 0 ,
Î±âˆ—

then it follows that for some i(cid:48) âˆˆ Cd(i), A(i, s) = A(i(cid:48), s) for all s âˆˆ S, which means that for
this i(cid:48), for all s âˆˆ S(i), s âˆˆ S(i(cid:48)), which would contradict the deï¬nition of Cd(i). Thus we
have

29

1
QN

(cid:80)

lim sup
Nâ†’âˆ

R(i)
log N

â‰¤ min
Î±âˆˆâˆ†(S(i))

max
i(cid:48)âˆˆCd(i)

(cid:80)

sâˆˆS(i) Î±s

(cid:18)
(cid:80)
U (i) âˆ’ [A(i, s) âˆ’ pâˆ—(s)]
sâˆˆS(i) Î±sI(i, i(cid:48)|s)

(cid:19)

.

Proposition 8.4. Suppose that the generalized imbalance condition is satisï¬ed. Consider
any optimal routing matrix xâˆ—. Then in the policy Ï€âˆ— for the N -job problem, for any N large
enough, one can choose a routing matrix yâˆ— such that yâˆ—(i, .) âˆˆ âˆ†(S(i)) and that satisï¬es:

iâˆˆC Ï0(i)Î¾Ï€âˆ—(i, s) = Â¯Âµ(s) for any s such that(cid:80)

iâˆˆC Ï0(i)xâˆ—(i, s) = Â¯Âµ(s), and

1. (cid:80)
2. (cid:80)
any feasible routing matrix [x(i, s)]CÃ—S. Consider any server s such that(cid:80)

We remark that the yâˆ— we construct satisï¬es (cid:107)yâˆ— âˆ’ xâˆ—(cid:107) = o(1).
In order to prove this proposition, we will need the following Lemma.

iâˆˆC Ï0(i)Î¾Ï€âˆ—(i, s) < Â¯Âµ(s) for any other s.

Lemma 8.5. Suppose that the generalized imbalance condition in (1) is satisï¬ed. Consider
iâˆˆC Ï0(i)x(i, s) =

Â¯Âµ(s). Then there is a path with the following properties:

â€¢ One end point is server s.
â€¢ The other end point is a server type whose capacity is under-utilized (it is permitted to

be Îº).

â€¢ For every client type and server type on the path in between, they are operating at

capacity/all jobs are being served.

â€¢ For every undirected edge on the path, there is a positive rate of jobs routed on that

edge in x.

Proof. Consider a bi-partite graph with servers representing nodes on one side and clients
on the other. There is an edge between a server s(cid:48) and a client i if x(i, s) > 0. Consider
the connected component of server s in this graph. Suppose it includes no server that is
underutilized. Then the arrival rate of jobs from the set of clients in the connected component
exactly matches the total eï¬€ective service rate of the sellers in connected component. But
this is a contradiction since generalized imbalance holds. Hence there exists an underutilized
server type s(cid:48) that can be reached from s. Take any path from s to s(cid:48). Traverse it starting
from s and terminate it the ï¬rst time it hits any underutilized server type.

Proof of Proposition 8.4. For a given routing matrix [y(i, s)]CÃ—S, let Î¾Ï€âˆ—(y)(i, s), be the result-
ing fraction of jobs directed from client type i to server type s. In the course of this proof, we
will suppress the subscript Ï€âˆ—(y). Clearly, there exist Îµi(cid:48)(i, s) for each i âˆˆ C, i(cid:48) âˆˆ Câˆª{0}, s âˆˆ S
such that we have

Î¾(i, s) = Îµ0(i, s) + (1 âˆ’ Îµi(i, s))y(i, s) +

30

(cid:88)

i(cid:48)âˆˆC\{i}

Îµi(cid:48)(i, s)y(i(cid:48), s) .

(17)

Let Sxâˆ— = {s : (cid:80)

The Îµâ€™s depend on the guessing and conï¬rmation phases but not on y. (In particular, Îµ0
arises from the overall routing contribution of the guessing and conï¬rmation phases, and Îµiâ€™s
arise from the small likelihood that a client who is conï¬rmed as type i is actually some other
type.) A key fact that we will use is that all Îµâ€™s are uniformly bounded by o(1).
iâˆˆC Ï0(i)Î¾Ï€âˆ—(i, s) = Â¯Âµ(s)}.
Now we want to ï¬nd a y such that y(i,Â·) âˆˆ âˆ†(S(i)) for all i âˆˆ C (call (i, s) a â€œpermissible
edgeâ€ in the bipartite graph between clients and servers if s âˆˆ S(i)), and such that:

iâˆˆC Ï0(i)xâˆ—(i, s) = Â¯Âµ(s)} and SÏ€âˆ— = {s : (cid:80)

â€¢ For each s âˆˆ Sxâˆ— we also have s âˆˆ SÏ€âˆ—, i.e., Sxâˆ— âŠ† SÏ€âˆ—.
â€¢ (cid:107)y âˆ’ xâˆ—(cid:107) = o(1).

Eq. (17), and this leads to (cid:80)

iâˆˆC Ï0(i)Î¾(i, s) = (cid:80)

Note that the two bullets together will imply the proposition, since (cid:107)Î¾ âˆ’ xâˆ—(cid:107) = o(1) from
iâˆˆC Ï0(i)xâˆ—(i, s) + o(1) < Â¯Âµ(s) for all s âˆˆ
S\Sxâˆ—, for large enough N .
Eq. (17). Here we write y (and later also xâˆ—) as a column vector with |C||S| elements:

The requirement in the ï¬rst bullet can be written as a set of linear equations using

By + Ë†Îµ = (Â¯Âµ(s))sâˆˆSxâˆ— .

Here we have (cid:107)Ë†Îµ(cid:107) = o(1) and matrix B can be written as B = B0 + BÎµ, where B0 has 1â€™s
in columns corresponding to dimensions (Â·, s) and 0â€™s everywhere else, and (cid:107)BÎµ(cid:107) = o(1).
Expressing y as y = x + z, we are left with the following equation for z,

Bz = âˆ’(BÎµxâˆ— + Ë†Îµ)

(18)
using the fact that B0xâˆ— = (Â¯Âµ(s))sâˆˆSxâˆ— by deï¬nitions of B0 and Sxâˆ—. We will look for a
solution to this underdetermined set of equations with a speciï¬c structure: we want z to be
a linear combination of ï¬‚ows along |Sxâˆ—| paths coming from Lemma 8.5, one path Î»s for each
s âˆˆ Sxâˆ—. Each Î»s can be written as a column vector with +1â€™s on the odd edges (including
the edge incident on s) and âˆ’1â€™s on the even edges. Let Î› = [Î»s]sâˆˆSxâˆ— be the path matrix.
Then z with the desired structure can be expressed as Î›Î·, where Î· is the vector of ï¬‚ows
along each of the paths. Now note that Bz = (B0 + BÎµ)Î›Î· = (I + BÎµÎ›)Î·. Here we deduced
B0Î› = I from the fact that Î»s is a path which has s as one end point, and a client or else a
server not in Sxâˆ— as the other end point. Our system of equations reduces to

(I + BÎµÎ›)Î· = âˆ’(BÎµxâˆ— + Ë†Îµ) ,

Since (cid:107)BÎµ(cid:107) = o(1), the coeï¬ƒcient matrix is extremely well behaved being o(1) diï¬€erent from
the identity, and we deduce that this system of equations has a unique solution Î·âˆ— that
satisï¬es (cid:107)Î·âˆ—(cid:107) = o(1). This yields us zâˆ— = Î›Î·âˆ— that is also of size o(1), and supported on
permissible edges since each of the paths is supported on permissible edges (Lemma 8.5).
Thus, we ï¬nally obtain yâˆ— = xâˆ— + zâˆ— possessing all the desired properties. Notice that the
(permissible) edges on which yâˆ— diï¬€ers from xâˆ— had strictly positive values in xâˆ— by Lemma
8.5, and hence this is also the case in yâˆ— for large enough N .

31

Proposition 8.6. Suppose that the generalized imbalance condition is satisï¬ed. Consider
the policy Ï€âˆ—, with the routing matrix yâˆ— and let W N (Ï€âˆ—) be the value attained by this policy
in optimization problem (2). Then

(cid:0)V âˆ— âˆ’ W N (Ï€âˆ—)(cid:1)

N

lim sup
Nâ†’âˆ

log N

(cid:80)

sâˆˆS(i) Î±s

(cid:18)
(cid:80)
U (i) âˆ’ [A(i, s) âˆ’ pâˆ—(s)]
sâˆˆS(i) Î±sI(i, i(cid:48)|s)
(cid:88)
Î¾Ï€âˆ—(i, s)A(i, s) âˆ’(cid:88)

max
i(cid:48)âˆˆCd(i)

pâˆ—(s)[

(cid:19)

.

sâˆˆS

iâˆˆC

â‰¤(cid:88)

iâˆˆC(cid:48)

Ï0(i) min

Î±âˆˆâˆ†(S(i))

(cid:88)
(cid:88)

iâˆˆC

(cid:88)
(cid:88)

sâˆˆS

W N

pâˆ— (Ï€âˆ—) =

Ï(i)

Proof. From Proposition 8.4 it follows that the policy Ï€âˆ— is feasible in problem 2, and further

Ï(i)Î¾Ï€âˆ—(i, s) âˆ’ Â¯Âµ(s)].

(19)

=

iâˆˆC

sâˆˆS

Ï(i)

Î¾Ï€âˆ—(i, s)A(i, s),

where the second equality follows from the fact that if pâˆ—(s) > 0, then (cid:80)
iâˆˆC Ï(i)xâˆ—(i, s) âˆ’
(cid:80)
Â¯Âµ(s) = 0 by complementary slackness, and hence from Proposition 8.4 we obtain that
iâˆˆC Ï(i)Î¾Ï€âˆ—(i, s) âˆ’ Â¯Âµ(s) = 0 as well for these s. Thus we have a policy Ï€âˆ— that is feasi-
pâˆ— (Ï€âˆ—) of accumulation of payoï¬€ in problem (2). Thus the result

(20)

ble, and that gives a rate W N
follows from Proposition 8.2

8.2 Other proofs

Proof of Proposition 5.1. Denote the eï¬€ective service rate of server type s by Â¯Âµ(s) = n(s)Âµ(s).
The dual to problem 4 can be written as

(cid:88)

sâˆˆS

(cid:88)

iâˆˆC

minimize

Â¯Âµ(s)p(s) +

Ï0(i)v(i)

subject to
p(s) + v(i) â‰¥ A(i, s) âˆ€i âˆˆ C, s âˆˆ S ,

p(s) â‰¥ 0 âˆ€s âˆˆ S ,
v(i) â‰¥ 0 âˆ€i âˆˆ C .

The dual variables are (P, V ) where â€œserver pricesâ€ P = (p(s))sâˆˆS and â€œclient valuesâ€ V =
(v(i))iâˆˆC. We will prove the result by contradiction. Suppose there are multiple dual optima.
Let D be the set of dual optima. Let S(cid:48) be the set of servers such that the prices of those
servers take multiple values in D. Formally,

S(cid:48) = {s âˆˆ S : p(s) takes multiple values in D} .

(21)

32

Similarly, let C(cid:48) be the set of clients such that the prices of those clients take multiple values
in D. Formally,

C(cid:48) = {i âˆˆ C : v(i) takes multiple values in D} .

(22)
For each s âˆˆ S(cid:48), we immediately deduce that there exists a dual optimum with p(s) > 0,
and hence the capacity constraint of server type s is tight in all primal optima. Similarly, we
sâˆˆS x(i, s) =

deduce that for each i âˆˆ C(cid:48), all arriving jobs from client type i are served, i.e.,(cid:80)

1. By assumption, we have

(cid:88)

iâˆˆC(cid:48)

(cid:88)

sâˆˆS(cid:48)

Ï0(i) (cid:54)=

Â¯Âµ(s) .

Suppose the left hand side is larger than the right (the complementary case can be dealt with
similarly). Take any primal optimum xâˆ—. The servers in S(cid:48) do not have enough capacity to
serve all clients in C(cid:48), hence there must be some client i âˆˆ C(cid:48) and a server s /âˆˆ S(cid:48) such that
xâˆ—(i, s) > 0. Since s /âˆˆ S(cid:48), we must have that p(s) has a unique optimum value in D. Call
this value pâˆ—(s). Let the largest and smallest values of v(i) in D be vmax(i) and vmin(i). By
complementary slackness, we know that

vmax(i) + pâˆ—(s) = A(i, s) = vmin(i) + pâˆ—(s)

â‡’ vmax(i) = vmin(i) .

But since i âˆˆ C(cid:48) we must have vmax(i) > vmin(i). Thus we have obtained a contradiction.

Proposition 8.7. Suppose that no two rows in A are identical. Then supxâˆˆD inf yâˆˆÎN (cid:107)x âˆ’
y(cid:107) = O( log N
N )
Proof. It is clear that ÎN âŠ† D. We will ï¬nd an inner approximation ËœÎN to ÎN such that
ËœÎN âŠ† ÎN , and ËœÎN converges to D in an appropriate sense as N goes to inï¬nity. To deï¬ne
this approximation, suppose that in the learning problem corresponding to a ï¬xed N , one
starts oï¬€ with a learning phase of a ï¬xed length O(log N ), where each server s is presented
to the client Os number of times (where Os = O(log N ), ï¬xed a priori), so that after this
phase, the type of the client becomes known with a probability of error at most O(1/N ).
This will then allow us to relate the problem to the problem in which the user type is known.
Suppose after this phase, the probability that a client of type b is correctly identiï¬ed is p(b)
and the probability that she is mis-identiï¬ed as some other type b(cid:48) is p(b, b(cid:48)). Note that
since no two rows in A are identical, p(b, b(cid:48)) = O(1/N ) for all b (cid:54)= b(cid:48). Let d(b, s) denote the
expected number of times a client that has been identiï¬ed as being of type b (correctly or
incorrectly) is directed towards server s after the learning phase, i.e., from job Os + 1 till the
N th job. Let Â¯d(b, s) = d(b, s)/N . Then we can see that, one can attain all Î¾ in the following
set:

(cid:26)

ËœÎN =

Î¾ âˆˆ R|B|Ã—|S| : Â¯d(b, s) â‰¥ 0;

Î¾(ib, s) = 1;

Î¾(b, s) =

Os
N

+ p(b) Â¯d(b, s) +

p(b, b(cid:48)) Â¯d(b(cid:48), s)

(cid:27)

(23)

(24)

(cid:88)
(cid:88)

sâˆˆS

b(cid:48)(cid:54)=b

33

Now since Â¯d(b, s) â‰¤ 1, and since p(b, b(cid:48)) â‰¤ O(1/N ), we can express the above set as:

ËœÎN =

Î¾ âˆˆ R|B|Ã—|S| : Â¯d(b, s) â‰¥ 0;

Î¾(b, s) = Â¯d(b, s) + O(

log N

N

)

(cid:26)

(cid:26)

Î¾(b, s) = 1;

(25)

(26)

(cid:27)

Î¾(b, s) = 1

(27)

(cid:88)

sâˆˆS

log N

N

);

(cid:88)
(cid:27)

sâˆˆS

),

)

Note that by construction, ËœÎN âŠ† ÎN . But we can now see that ËœÎN converges to D in the
sense that

This in turn is the same as:

ËœÎN =

Î¾ âˆˆ R|B|Ã—|S| : Î¾(b, s) â‰¥ O(

sup
xâˆˆD

inf
yâˆˆËœÎN

(cid:107)x âˆ’ y(cid:107) = O(

log N

N

and hence,

as well.

sup
xâˆˆD

inf
yâˆˆÎN

(cid:107)x âˆ’ y(cid:107) = O(

log N

N

Proposition 8.8. The set ÎN is a convex polytope.

Proof. For the purpose of this proof, let

N

Î

= {N Î¾ : Î¾ âˆˆ ÎN}.

N

N

N +1

0
Now clearly, Î

is a polytope, from which the result will follow. We will prove this
We will show that Î
as a |C| Ã— |S| matrix
using an induction argument. We will represent each point in Î
(Î¾(i, s))|C|Ã—|S|. Let client types in C be labeled as i1, . . . , i|C| and let server types in S be
labeled as s1, . . . , s|S|.

= {(0)|C|Ã—|S|} which is a convex polytope. We will show that if Î

is a
convex polytope, then Î
is one as well, and hence the result will follow. To do so, we de-
compose the assignment problem with N +1 jobs, into the ï¬rst job and the remaining N jobs.
A policy in the N + 1- jobs problem is a choice of a randomization over the servers in S
for the ï¬rst job, and depending on whether a reward was obtained or not with the chosen
server, a choice of a point in Î
to be achieved for the remaining N jobs. Each such policy
. Suppose that Î·1 âˆˆ âˆ†(S) is the randomization chosen for job
gives a point in the Î
and R(s, 0) âˆˆ Î
1, and let R(s, 1) âˆˆ Î
N
be the points chosen to be achieved from job 2
onwards depending on the server s that was chosen, and whether a reward was obtained or

N +1

N

N

N

34

not, i.e.. R(., .) is a mapping from S Ã— {0, 1} to the set Î
following point in the N + 1- jobs problem:

N

. Then this policy achieves the

Diag[A(., s)]R(s, 1) + Diag[ Â¯A(., s)]R(s, 0)

,

(cid:19)

ï£®ï£¯ï£°Î·1(s1) Î·1(s2)

...

...

Î·1(s1) Î·1(s2)

. . .
. . .
. . .

Î·1(s|S|)

...

Î·1(s|S|)

ï£¹ï£ºï£» +

sâˆˆS

0
...
0

Î·1(s)

(cid:18)
(cid:88)
ï£®ï£¯ï£¯ï£¯ï£°A(i1, s)
ï£®ï£¯ï£¯ï£¯ï£°1 âˆ’ A(i1, s)
ï£¹ï£ºï£» +
(cid:88)

Î·1(s|S|)

0
...
0

...

sâˆˆS

Î·1(s|S|)

N(cid:27)

.

ï£¹ï£ºï£ºï£ºï£»

0

A(i2, s)

...
0

0
0

. . .
. . .
. . .
. . . A(i|C|, s)

0

1 âˆ’ A(i2, s)

. . .
. . .
. . .
. . .

0
0

0

1 âˆ’ A(i|C|, s)

ï£¹ï£ºï£ºï£ºï£» .

0

...
0

(cid:18)

Î·1(s)

Diag[A(., s)]R(s, 1) + Diag[ Â¯A(., s)]R(s, 0)

(cid:19)

where

and

Diag[A(., s)] =

Diag[ Â¯A(., s)] =

And thus we have

Î

N +1

=(cid:26)ï£®ï£¯ï£°Î·1(s1) Î·1(s2)

...

...

Î·1(s1) Î·1(s2)

. . .
. . .
. . .

: Î·1 âˆˆ âˆ†(S), R(., .) âˆˆ Î

Let 1s be the |C|Ã—|S| matrix with ones along column corresponding to server type s and

all other entries 0. Then the set

J (s) =

1s + Diag[A(., s)]R(s, 1) + Diag[ Â¯A(., s)]R(s, 0) : R(s, .) âˆˆ Î

N(cid:27)

,

(cid:26)

is a convex polytope, being a linear combination of two convex polytopes, followed by an
is just a convex combination of the polytopes J (s)
aï¬ƒne shift. It is easy to see that Î
for s âˆˆ S, and hence Î

is a convex polytope as well.

N +1

N +1

35

