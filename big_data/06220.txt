Flow of Information in Feed-Forward Deep Neural

Networks

Pejman Khadivi

Computer Science Department
Virginia Tech, Virginia, USA

Email: pejman@vt.edu

Ravi Tandon

Electrical and Computer Engineering Department

University of Arizona, Arizona, USA
Email: tandonr@email.arizona.edu

Naren Ramakrishnan

Computer Science Department
Virginia Tech, Virginia, USA

Email: naren@cs.vt.edu

6
1
0
2

 
r
a

 

M
0
2

 
 
]
T
I
.
s
c
[
 
 

1
v
0
2
2
6
0

.

3
0
6
1
:
v
i
X
r
a

Abstractâ€”Feed-forward deep neural networks have been used
extensively in various machine learning applications. Developing
a precise understanding of the underling behavior of neural
networks is crucial for their efï¬cient deployment. In this paper,
we use an information theoretic approach to study the ï¬‚ow of
information in a neural network and to determine how entropy of
information changes between consecutive layers. Moreover, using
the Information Bottleneck principle, we develop a constrained
optimization problem that can be used in the training process
of a deep neural network. Furthermore, we determine a lower
bound for the level of data representation that can be achieved
in a deep neural network with an acceptable level of distortion.

I. INTRODUCTION

With the increasing demand for data analytics, Big Data, and
artiï¬cial intelligence, efï¬cient machine learning algorithms are
required now more than anytime before [1]. Deep learning and
deep neural networks (DNNs) have been shown to be among
the most efï¬cient machine learning paradigms, speciï¬cally
for supervised learning tasks. Due to their fascinating perfor-
mance, different deep learning structures have been deployed
in various applications in the past decades [1], [2], [3].
However, despite of their great performance, more theoretical
effort is required to understand the dynamic behavior of DNNs
both from learning and design perspectives.

Deep neural networks are considered as multi-layer struc-
tures, constructed by simple processing units known as neu-
rons that process the input information to generate a desired
output [4], [5]. These structures have been used previously in
a variety of applications, such as dimensionality reduction [6],
face representation [2], robotic grasps detection [3], and object
detection [7].

While DNNs have shown their capability in solving machine
learning problems, they have been traditionally deployed in
a heuristic manner [8], [9]. However,
to be able to use
these structures more efï¬ciently, we need to have a deeper
understanding of their underling dynamic behavior [9].

Mehta and Schwab shown in [10] that deep learning is
related to renormalization groups in theoretical physics and
provide a mapping between deep learning methods and vari-
ational renormalization groups using Restricted Boltzmann
Machines. In [8], Tishby and Zaslavsky proposed a theoretical
framework, based on the principle of Information Bottleneck
[11], to analyze the DNNs where, the ultimate goal of deep

learning has been formulated as a trade-off between com-
pression and prediction. In [8],
the authors claim that an
optimal point exists on the compression-distortion plane that
can efï¬ciently address that trade-off. Moreover, they suggest
that an Information Bottleneck based learning algorithm may
achieve the optimal information representation.

In this paper, we analyze the ï¬‚ow of information in a deep
neural network using an information theoretic approach. While
different structures have been developed for DNNs, in this
paper, we consider the multi-layer feed-forward structure and
we assume that the network is used in a supervised setting.
We determine an upper bound on the total compression rate in
a neural network that can be achieved with an acceptable level
of distortion. Furthermore, using the fundamental concepts of
Information Bottleneck and based on the approach of Tishby
and Zaslavsky in [8], we develop an optimization problem that
can be used in the learning process of DNNs. A case study
supports the justiï¬cations of the paper. Thus, our contributions
and the structure of the paper are as follows:

â€¢ In Section II, we focus on the information ï¬‚ow across
any two consecutive layers of a DNN by characterizing
the relative change in the entropy across layers and also
developing some properties of the same.

â€¢ In Section III, motivated by the Information Bottleneck
principle, we deï¬ne an optimization problem for training
a DNN, in which the goal is to minimize the overall log-
loss distortion. Moreover, we prove an upper bound on
the total data compression which is achievable in a DNN
with an acceptable level of distortion.

â€¢ In Section IV we modify the optimization problem of
Section III to address the practical limitations of neural
computation. We ï¬rst illustrate that how the results of the
original optimization model may be unfeasible and then,
by adding sufï¬cient constraints to the model we propose
a modiï¬ed optimization problem that can be used in the
training process of a DNN.

II. FLOW OF ENTROPY IN DEEP NEURAL NETWORKS
The typical structure of a feed-forward DNN is illustrated
in Fig 1. In this ï¬gure, input layer is represented by X and
the representation of data in the ith hidden layer is shown
by Xi. We assume that the network has Î½ layers and the
output layer, i.e. XÎ½, should estimate a desired output, Y .

and in this case, we have kn < knâˆ’1.

It worth mentioning that the mapping in each layer of DNN is
also a partitioning of the layerâ€™s input space and hence, what a
DNN does is multiple consecutive of partitioning and mapping
processes with goal of estimating of a desired output.

Deï¬nition 1: In the nth layer of a feed-forward DNN, layer
partition is the partitioning of the nth layerâ€™s input space
which occurs due to the neural computations performed in
layer n. We illustrate this partitioning by Sn = {Sn
}
1 ,Â·Â·Â· , Sn
kn
is the set of all the output combinations in layer
where, Sn
j
n âˆ’ 1 that are mapped to the jth output combination in layer
n, i.e. xn

j . In other words,
j = { xnâˆ’1
Sn

âˆˆ Xnâˆ’1 | xn

i
Note that we have:
i (cid:54)= j â‡’ Sn

)}

i

j = Gn(xnâˆ’1
kn(cid:91)

j=1

i âˆ© Sn

j = âˆ…

and

j = Xnâˆ’1.
Sn

Let us assume that Pn(xn

j ) is the probability of xn

j . Then,

it can be observed that

Pn(xn

j ) =

Pnâˆ’1(x(cid:48))

(3)

(cid:88)

x(cid:48)âˆˆSn

j

Furthermore, considering this fact that Sn is a partitioning of
Xnâˆ’1, one can easily show that Pn(xn
j ) is the probability of
partition Sn

j . It can be shown that

(cid:40)

Î n

j =

âˆ€x âˆˆ Sn
j |

(cid:41)

(cid:80)

Pnâˆ’1(x)

Pnâˆ’1(x(cid:48))

x(cid:48)âˆˆSn

j

(4)

is the probability distribution of all the combinations in Sn
j .
Deï¬nition 2: In a feed-forward DNN, the entropy of layer
n, H(Xn), is the entropy of the neuron outputs at this layer
and we have:

H(Xn) = âˆ’ kn(cid:88)

i=1

Pn(xn

i ) log Pn(xn

i ).

Deï¬nition 3: The entropy of partition Sn

j , H(Sn
entropy of the output combinations that belong to Sn
words:

j ), is the
j . In other

j ) = âˆ’ (cid:88)

(cid:80)

H(Sn

Pnâˆ’1(x)

Pnâˆ’1(x(cid:48))

log

Pnâˆ’1(x)

Pnâˆ’1(x(cid:48))

x(cid:48)âˆˆSn

j

xâˆˆSn

j

x(cid:48)âˆˆSn

j

(cid:80)

In the following lemma we show how entropy of informa-

tion changes in a feed-forward neural network.

Lemma 1: In a feed-forward DNN, the entropy of informa-
tion that ï¬‚ows from layer n âˆ’ 1 to layer n is decreased by
the expected entropy of the partitions on the possible output
combinations in layer n âˆ’ 1. The amount of this reduction is
shown by âˆ†n and we have

âˆ†n = H(Xnâˆ’1) âˆ’ H(Xn) =

Pn(xn

j )H(Sn

j ).

(5)

kn(cid:88)

j=1

(cid:32)mnâˆ’1(cid:88)

Fig. 1. General structure of a feed-forward deep neural network.

Each layer is constructed by multiple neurons that process the
information in parallel and the output of the jth neuron in
layer n is calculated as follows:

(cid:33)

i=1

wn

xn,j = gn

i,jxnâˆ’1,i + bn
j

j (xnâˆ’1) = f n

(1)
where mnâˆ’1 is the number of neurons in layer nâˆ’ 1 and wn
i,j
is a weight that connects the output of the ith neuron in layer
n âˆ’ 1 to the input of the jth neuron in layer n. Also, bn
j is
the bias of the jth neuron in layer n and f n(Â·) is the output
function of the neurons in this layer. To illustrate (1) in vector
notation we say:

xn = Gn(xnâˆ’1)

(2)
where xn is a combination of neuron outputs in layer n,
i.e. xn = [xn,1,Â·Â·Â· , xn,mn ]. The total number of possible
output combinations in the nth layer is illustrated by kn which
depends on the output functions and the input space. As an
example, with binary output functions, kn = 2mn. At the nth
layer, Xn = {xn
} is the set of all possible output
combinations. It should be noted that a single neuron has a
very limited processing capability. As a matter of fact, an
individual neuron can only implement a hyper-plane in its
input space and hence, not all the mappings from its input
to its output are feasible. This limitation is one of the main
reasons that neural networks are constructed by multiple layers
of interacting neurons.

1,Â·Â·Â· , xn

kn

The neural computation that occurs in each layer performs
a mapping between the outputs of the consecutive layers. In
other words, various output combinations in layer n âˆ’ 1 are
mapped to certain output combinations in layer n. Depending
on the weights, bias, and the output function in layer n, there
are two possibilities:
â€¢ Each unique combination of neuron outputs in layer nâˆ’1
is uniquely mapped to a combination of neuron outputs
in layer n. In other words:

âˆ€x1, x2 âˆˆ Xnâˆ’1 âˆ´ Gn(x1) (cid:54)= Gn(x2)

In this case, regardless of the number of neurons in each
layer, we have kn = knâˆ’1.
â€¢ Multiple (at least two) combinations of neuron outputs in
layer nâˆ’1 are mapped to a single combination of neuron
outputs in layer n. In other words:

âˆƒx1, x2 âˆˆ Xnâˆ’1 âˆ´ Gn(x1) = Gn(x1)

............ğ‘‹ğ‘‹1ğ‘‹2â€¦ğ‘‹ğœˆâˆ’1ğ‘‹ğœˆ= ğ‘ŒInput SpaceOutput Spaceknâˆ’1(cid:88)

i=1

i=1

ï£±ï£²ï£³knâˆ’1(cid:88)
ï£®ï£°ï£«ï£­(cid:88)
kn(cid:88)
ï£«ï£­(cid:88)

j=1

xâˆˆSn

j

xâˆˆSn

j

H(Xn) = âˆ’

+

âˆ’

j

xâˆˆSn

(cid:16)(cid:80)
hand, we have:ï£«ï£­(cid:88)
ï£«ï£­(cid:88)
= âˆ’ (cid:88)

xâˆˆSn

xâˆˆSn

âˆ’

j

j

In other words, we started from the entropy of Xnâˆ’1 and
substituted the individual
the output combi-
j with their new equivalent term,
nations that belong to Sn
. On the other
i.e.
log

terms of all

Pnâˆ’1(x)

Pnâˆ’1(x)

(cid:17)

(cid:16)(cid:80)
ï£¶ï£¸ log

j

xâˆˆSn

ï£«ï£­(cid:88)

xâˆˆSn

j

Pnâˆ’1(x)

Pnâˆ’1(x)

Pnâˆ’1(x) log Pnâˆ’1(x)

(cid:80)

Pnâˆ’1(x) log

xâˆˆSn

j

Pnâˆ’1(x)

Pnâˆ’1(x(cid:48))

x(cid:48)âˆˆSn

j

then, considering (6), we can rewrite (7) as follows:

kn(cid:88)

(cid:88)

j

xâˆˆSn
Equivalently, we have

+

j=1

kn(cid:88)

Pnâˆ’1(x) log

H(Xn) = H(Xnâˆ’1)

H(Xn) = H(Xnâˆ’1) +

(cid:80)
ï£«ï£­ (cid:88)
ï£«ï£­(cid:88)
(cid:80)
(cid:80)
H(Xn) = H(Xnâˆ’1) âˆ’ kn(cid:88)

Pnâˆ’1(x(cid:48))

Pnâˆ’1(x)

x(cid:48)âˆˆSn

x(cid:48)âˆˆSn

xâˆˆSn

log

j=1

Then, based on Deï¬nition 3 we can say:

j

j

j

Pnâˆ’1(x)

Pnâˆ’1(x(cid:48))

x(cid:48)âˆˆSn

j

(8)

ï£¶ï£¸

Pnâˆ’1(x(cid:48))

ï£¶ï£¸ (9)

Pnâˆ’1(x)

Pnâˆ’1(x(cid:48))

x(cid:48)âˆˆSn

j

The following lemma proves a similar result for the ï¬‚ow of

conditional entropy in a deep neural network.

Lemma 2: In a feed-forward DNN, the conditional entropy
i.e.

of each layer, conditioned on the desired outputs, Y ,
H(Xn|Y ), is a non-increasing function of n and we have:

n = H(Xnâˆ’1|Y ) âˆ’ H(Xn|Y )
âˆ†(cid:48)

(cid:88)

kn(cid:88)

yâˆˆY

j=1

=

PY (y)Pn(xn

j |Y = y)H(Sn

j |y)

(11)

where

Pn(xn

j |Y = y) =

(cid:88)

xâˆˆSn

j

Pnâˆ’1(x|Y = y)

and

(7)

j |y) = âˆ’ (cid:88)

xâˆˆSn

j

H(Sn

Pnâˆ’1(x|Y = y)
j |Y = y)
Pn(xn

log

Pnâˆ’1(x|Y = y)
j |Y = y)
Pn(xn

.

Proof: The proof of Lemma 2 follows on similar lines as
Lemma 1 by conditioning on the random variable Y and is
therefore omitted.

III. OPTIMAL MAPPING AND INFORMATION BOTTLENECK

Extraction of relevant information from an input data with
respect to a desired output is one of the central issues in super-
vised learning [12]. In information theoretic terms, assuming
that X and Y are the input and output random variables,
I(X; Y ) is the relevant information between X and Y . In
order to improve the efï¬ciency of a machine learning task, we
generally need to extract the minimal sufï¬cient statistics of X
with respect to Y . Hence, as the Information Bottleneck prin-
ciple [11] indicates, we need to ï¬nd a maximally compressed
representation of X by extracting the relevant information with
respect to Y [8]. In this section, we follow the approach of
[8] to deï¬ne an optimization problem that can be used in the
learning process of a DNN. We also prove an upper bound on
the achievable compression rate of the input in DNNs.
Consider a DNN with Î½ layers. Let us assume that Ë†X =
[X1,Â·Â·Â· , XÎ½] denotes the output of these layers. To ï¬nd
the maximally compressed representation of X, we need to
minimize the mutual information between the input, i.e. X,
and the representation of data by the DNN, Ë†X. This can
be formulated as minimizing the mutual information between
the input and the representation of data in each layer, i.e.
Xi, i = 1,Â·Â·Â· , Î½ which can be modeled as

Î½(cid:88)

min

I(X; Xi).

(12)

Proof: Let us assume that the information has been pro-
cessed up to layer Xnâˆ’1. Using Deï¬nition 2, the entropy of
layer n âˆ’ 1 is

H(Xnâˆ’1) = âˆ’

Pnâˆ’1(xnâˆ’1

i

) log Pnâˆ’1(xnâˆ’1

i

)

(6)

To determine H(Xn), we can say

Pnâˆ’1(xnâˆ’1

) log Pnâˆ’1(xnâˆ’1

)

i

ï£¶ï£¸ log

Pnâˆ’1(x)

Pnâˆ’1(x)

ï£¶ï£¸

Pnâˆ’1(x) log Pnâˆ’1(x)

j

i

xâˆˆSn

ï£«ï£­(cid:88)
ï£¶ï£¸ï£¹ï£»ï£¼ï£½ï£¾
(cid:17)

ï£¶ï£¸

ï£¶ï£¸

Pn(xn

j )H(Sn
j )

(10)

i=1

j=1

and n is(cid:80)kn

and from here, we can observe that H(Xn) â‰¤ H(Xnâˆ’1).
Furthermore, the difference between the entropy in layers nâˆ’1
j ) which is the expected entropy
of the partitions on Xnâˆ’1. This proves the lemma.

j=1 Pn(xn

j )H(Sn

To measure the ï¬delity of the training process of a feed-
forward DNN, we focus on the Logarithmic-loss distortion
function. Let p(y|x) denotes the conditional distribution of Y
given X (i.e., the original input data) and similarly, let p(y|Ë†x)
denotes the conditional distribution of Y given Ë†X (i.e., given

the outputs of all the layers). Then, one measure of ï¬delity is
the KL-divergence between these distributions:
P (y|x)
P (y|Ë†x)

P (y|x) log

dIB(x, Ë†x) =

(cid:88)

(13)

y

and taking the expectation of dIB(x, Ë†x) we get:
DIB = E [dIB(x, Ë†x)] = I(X; Y | Ë†X)

(14)

Using the Markov chain properties of the feed-forward net-
work, one can show that
I(X; Y | Ë†X) = I(X; Y | [X1,Â·Â·Â· , XÎ½]) = I(X; Y |XÎ½) (15)
and hence, the overall distortion of the DNN will be DIB =
I(X; Y |XÎ½). Therefore, using the Information Bottleneck
principle, the training criteria for a feed-forward DNN can
be formulated as follows

Î½(cid:88)

min
I(X; Xi)
I(X; Y |XÎ½) â‰¤ 

i=1

s.t.

(16)

As we have mentioned in Section II, in the ith layer, each
input combination is mapped to a speciï¬c output combination.
Therefore, it can be easily shown that H(Xi|X) = 0 and
hence, I(X; Xi) = H(Xi). Then, using Lemma 1 we have:

I(X; Xi) = H(X) âˆ’ i(cid:88)

âˆ†j.

(17)

j=1

Note that in the above equation, H(X) is constant, i.e. it does
not depend on the neural network settings.

Regarding the constraint of (16), it can be shown that

I(X; Y |XÎ½) = I(X; Y ) âˆ’ I(XÎ½; Y )

(18)
On the other hand, we know that I(XÎ½; Y ) = H(XÎ½) âˆ’
H(XÎ½|Y ) and using Lemma 1 and Lemma 2, we have

(cid:40)

H(XÎ½) = H(X) âˆ’(cid:80)Î½
H(XÎ½|Y ) = H(X|Y ) âˆ’(cid:80)Î½

i=1 âˆ†i

i=1 âˆ†(cid:48)

i

which results in the following equation:

I(X; Y |XÎ½) =

(âˆ†i âˆ’ âˆ†(cid:48)

i) .

(19)

Using (17) and (19) and by minor manipulation, the opti-

mization problem of (16) can be rewritten as follows:

In the optimization problem of (20), âˆ†i

is the amount
of entropy reduction in layer i which can be interpreted
as the amount of data compression that has been occurred
at this layer. Moreover, we can observe that the total data
compression (i.e. reduction in entropy) that occurs in DNN is

(cid:80) âˆ†i and is deï¬ned in the following deï¬nition:

Deï¬nition 4: The total compression in a feed forward DNN

with Î½ layers is illustrated by CÎ½ and we have:

Î½(cid:88)

i=1

CÎ½ =

âˆ†i

Î½(cid:88)

Î½(cid:88)

i=1

The following lemma shows an upper bound on CÎ½:
Lemma 3: In a multilayer neural network with input X, out-
put layer XÎ½, and the desired output Y , the maximum possible
entropy reduction from the input space to the output space that
satisï¬es the distortion constraint is H(X|Y ) âˆ’ H(XÎ½|Y ).

Proof: From the constraint of (20) we have:

âˆ†(cid:48)

âˆ†i â‰¤  +
(21)
i = H(Xiâˆ’1|Y )âˆ’H(Xi|Y ). Hence,

i=1

i

Î½(cid:88)

However, we know that âˆ†(cid:48)
we have
i = H(X|Y ) âˆ’ H(X1|Y ) + H(X1|Y ) âˆ’ H(X2|Y )
âˆ†(cid:48)
+ H(X2|Y ) âˆ’ Â·Â·Â· âˆ’ H(XÎ½|Y ) = H(X|Y ) âˆ’ H(XÎ½|Y )

i=1

Therefore, using Deï¬nition 4 and (21) and when  â†’ 0 we
have:

CÎ½ â‰¤ H(X|Y ) âˆ’ H(XÎ½|Y )

(22)

This proves the lemma.

The ï¬rst consequence of Lemma 3 is that, regardless of the
number of layers, CÎ½ cannot be greater than H(X|Y ). In fact,
considering Lemma 2, H(Xi|Y ) is a non-increasing function
of i, and hence we have:

CÎ½ â‰¤ H(X|Y )

(23)

However, it should be noted that higher number of layers
may result in a more compressed representation of data. In
other words, based on Lemma 2, for Î½1 > Î½2 we have
H(XÎ½1|Y ) â‰¥ H(XÎ½2|Y ) and hence, CÎ½1 â‰¤ CÎ½2. In the next
section, we indicate that due to the structural limitations of
an artiï¬cial neuron, not all the mappings determined by (20)
can be implemented using one layer. Therefore, in addition
to have a more compressed representation of information, in
a neural network multiple layers may be required to achieve
feasible mappings from the input space to the output space.

Î½(cid:88)

i=1

Î½âˆ’1(cid:88)

(Î½ âˆ’ i)âˆ†i+1

i=0

(âˆ†i âˆ’ âˆ†(cid:48)

i) â‰¤ 

max

Î½(cid:88)

i=1

s.t.

This is a convex optimization problem and due to its com-
plexity, it is generally difï¬cult to ï¬nd an analytic solution for
that. However, numerical solutions (such as algorithms based
on Blahut-Arimoto [13]) may be deployed here to solve (20).

(20)

IV. FEASIBLE OPTIMAL MAPPINGS

While the optimization problem of (20) can be used to ï¬nd
the optimal mappings between consecutive layers of a neural
network, it may result in unfeasible solutions. As a matter of
fact, a single neuron implements a single hyperplane in the
input space and hence, only linearly separable classiï¬cation

{ ËœÎ˜1,n,Â·Â·Â· , ËœÎ˜Îºn,n} is the set of forbidden mappings. Then,
the optimization problem of (20) can be modiï¬ed as follows:

(Î½ âˆ’ n)Î¸n+1

ij Pn(xn

i ) log

Pn+1(xn+1
j
Pn(xn
i )

)

(cid:18)

Pnâˆ’1(xnâˆ’1

i

Î¸n
ijPY (y)

âˆ’Pnâˆ’1(xnâˆ’1

i

|Y = y) log

kn(cid:88)
kn+1(cid:88)
Î½âˆ’1(cid:88)
knâˆ’1(cid:88)
kn(cid:88)
(cid:88)

n=0

j=1

i=1

max

s.t.

Î½(cid:88)

n=1

yâˆˆY

j=1

i=1

kn(cid:88)

j=1

Pn(xn
j )
Pnâˆ’1(xnâˆ’1

i

) log
j |Y = y)

(cid:19)

Pn(xn

)
â‰¤ 

i

Pnâˆ’1(xnâˆ’1

|Y = y)
i = 1,Â·Â·Â· , knâˆ’1
i = 1,Â·Â·Â· , Îºn

,

ij = 1 , n = 1,Â·Â·Â· , Î½
Î¸n
, n = 1,Â·Â·Â· , Î½

,

Î˜n (cid:54)= ËœÎ˜i,n
where the solution to (28) is the set of Î¸ijâ€™s. Note that the
last statement is used to exclude the forbidden mappings from
the set of solutions. The optimization problem of (28) ï¬nds
the optimal mappings between any two consecutive layers in a
feed-forward DNN. These mappings can then be implemented
by proper selection of neuron weights.

(28)

V. CASE STUDY: BOOLEAN FUNCTIONS

In this section, we perform a case study to observe how
the proposed optimization problem of (28) may be used to
determine optimal mappings between consecutive layers in
a DNN. For this study, we try to implement basic boolean
functions and show how entropy changes from the input to the
output layer. In this set of experiments we use AND, OR, and
XOR functions with two and three inputs and we assume that
Î½ âˆˆ {1, 2, 3}. Results are illustrated in Table I. It is clear from
these results that feasible mappings cannot be determined for
two and three input XOR functions when Î½ = 1. As we have
mentioned before, this is due to the processing limitations of
a single neuron. However, for AND and OR functions even
one single neuron was able to implement the function. Figure 3
shows an example set of mappings between consecutive layers
for XOR function using a two-layer neural network.
Table I also illustrates the achievable compression rate, i.e.
CÎ½, and its corresponding upper bound, i.e. H(X|Y ). As we
can observe, in the cases that the function was implementable
using the neural network, CÎ½ is equal to H(X|Y ), which
means that for these functions we have been able to achieve
the minimum representation of data at the output layer. As we
proved in Lemma 3, we observe that the maximum achievable
level of data compression in a feed-forward DNN is H(X|Y ).
Moreover, results indicate that the main reason to add an extra
layer to a DNN is to achieve feasible mappings. However, as
Lemma 3 shows, extra layers may lead to a more compressed
representation of the input data.

VI. CONCLUSION

In this paper, we used information theory methods to study
the ï¬‚ow of information in DNNs. We determined how entropy

(a)

(b)

Fig. 2.
(a) Examples of feasible and unfeasible mappings. Black and white
circles are mapped to outputs â€™1â€™ and â€™0â€™ respectively. (b) Unfeasible mappings
resulted from the optimization problem of (20) with a single neuron.

problems may be solved with a single neuron. As an example,
in binary input/output space (i.e. when the inputs and the
output of the neuron are binary), an XOR function cannot
be implemented with a single neuron. Examples of feasible
and unfeasible mappings with a single neuron are illustrated
in Fig. 2(a). In this ï¬gure, black and white circles are mapped
to outputs â€™1â€™ and â€™0â€™, respectively. However, a single neuron
can only divide the space into two parts and hence,
the
top mapping (i.e. boolean OR function) can be implemented
by a single neuron while the bottom mapping (i.e. boolean
XOR function) is not implementable. The unfeasible mappings
which are resulted from the optimization problem of (20) for a
boolean XOR function are illustrated in Fig. 2(b). Therefore,
we need to add more constraints to the above optimization
problems to exclude the unfeasible mappings.

Using (5) and the deï¬nition of H(Sn

j ) we can show that

kn(cid:88)

(cid:88)
(cid:40)

âˆ†n =

j=1

xâˆˆSn

j

Pnâˆ’1(x) log

Pn(xn
j )
Pnâˆ’1(x)

Let us deï¬ne the following parameter:
âˆˆ Sn
, xnâˆ’1
j
, Otherwise

Î¸n
ij =

1

0

i

(24)

(25)

j=1 Î¸ij = 1. Moreover, in vector notations, Î˜n is a
ij. Then, (24) can be

knâˆ’1 Ã— kn matrix such that Î˜n[i, j] = Î¸n
written as follows

where,(cid:80)kn
kn(cid:88)

âˆ†n =

knâˆ’1(cid:88)

Furthermore, using a similar notation, it can be shown that

Pn(xn
j )
Pnâˆ’1(xnâˆ’1

i

(26)

)

i

) log

ijPnâˆ’1(xnâˆ’1
Î¸n
knâˆ’1(cid:88)
Î¸ijPY (y)Pnâˆ’1(xnâˆ’1
j |Y = y)

i=1
Pn(xn

i

j=1

i=1

(cid:88)

kn(cid:88)

j=1

yâˆˆY

log

Pnâˆ’1(xnâˆ’1

i

|Y = y)

âˆ†(cid:48)
n =

|Y = y)

(27)

As we mentioned before, not all the mappings between
the inputs and outputs of a neuron are feasible. Unfeasible
mappings depend on the structure of the network, number of
neurons in each layer, and the corresponding output functions
in each layer. Let us assume that at the nth layer, ËœÎ˜n =

â€™00â€™â€™01â€™â€™10â€™â€™11â€™â€™00â€™â€™01â€™â€™10â€™â€™11â€™FeasibleUnfeasibleâ€™00â€™â€™01â€™â€™10â€™â€™11â€™ğ‘‹ğ‘‹1= ğ‘Œ[12] T.G. Dietterich, Structural, Syntactic, and Statistical Pattern Recogni-
tion: Joint IAPR International Workshops SSPR 2002 and SPR 2002
Windsor, Ontario, Canada, August 6â€“9, 2002 Proceedings, chapter
Machine Learning for Sequential Data: A Review, pp. 15â€“30, Springer
Berlin Heidelberg, Berlin, Heidelberg, 2002.

[13] R.E. Blahut,

â€œComputation of channel capacity and rate-distortion
functions,â€ Information Theory, IEEE Trans. on, vol. 18, no. 4, pp.
460â€“473, April 1972.

CASE STUDY RESULTS FOR BOOLEAN FUNCTIONS.

TABLE I

Function
(Inputs)
AND (2)
OR (2)âˆ—
XOR (2)
AND (2)
XOR (2)
AND (2)
XOR (2)
AND (3)
XOR (3)

Î½

1
1
1
2
2
3
3
1
1

Neurons
per Layer

[1]
[1]
[1]
[2 1]
[2 1]
[2 2 1]
[2 2 1]

[1]
[1]

Solution
Exists?

Yes
Yes
No
Yes
Yes
Yes
Yes
Yes
No

Optimization

Function

1.189
0.888

2.377
1.500
3.566
2.500
2.456

-

-

CÎ½

H(X|Y )

1.189
0.888

1.189
1.000
1.189
1.000
2.456

-

-

1.189
0.888

1.189
1.000
1.189
1.000
2.456

-

-

(*) Distribution is not uniform: Probability of 00 is 0.7 and others are 0.1.

Fig. 3. An example sequence of mappings for XOR.

and conditional entropy of information changes between con-
secutive layers and using the Information Bottleneck principle
we modeled the learning process of a feed-forward neural
network as a constrained optimization problem. Furthermore,
we proved an upper bound for the total compression rate of
information that can be achieved in a neural network while the
overall distortion in the output layer with respect to a desired
output is in an acceptable range. In this paper, we assumed that
the neural network is used for supervised learning tasks and
the input/output spaces are based on discrete alphabets. For the
future work, we aim to extend our work to a broader range of
learning problems and to include continues input/output spaces
in our model.

REFERENCES

[1] X.W. Chen and X.Lin,

â€œBig data deep learning: Challenges and

perspectives,â€ IEEE Access, vol. 2, no. 2, pp. 514â€“525, 1991.

[2] Y. Sun, X. Wang, and X. Tang, â€œDeep learning face representation
from predicting 10,000 classes,â€ in Proc. of the CVPRâ€™14, 2014, pp.
1891â€“1898.

[3] I. Lenz, H. Lee, and A. Saxena, â€œDeep learning for detecting robotic
grasps,â€ The International Journal of Robotics Research, vol. 34, no.
4-5, April 2015.

[4] T.M. Mitchell, Machine Learning, McGraw-Hill, 1997.
[5] J. Schmidhuber, â€œDeep learning in neural networks: An overview,â€ Tech.
Rep. IDSIA-03-14, The Swiss AI Lab IDSIA, University of Lugano &
SUPSI, Swiss, 2014.

[6] G. E. Hinton and R. R. Salakhutdinov, â€œReducing the dimensionality of
data with neural networks,â€ Science, vol. 313, no. 5786, pp. 504â€“507,
2006.

[7] C. Szegedy, A. Toshev, and D. Erhan, â€œDeep neural networks for object

detection,â€ in Proc. of NIPSâ€™13, 2013, pp. 2553â€“2561.

[9] C. M. Bishop,

â€œTheoretical foundations of neural networks,â€

in

Proceedings of Physics Computing, 1996, pp. 500â€“507.

[10] P. Mehta and D. J. Schwab, â€œAn exact mapping between the Variational
Renormalization Group and Deep Learning,â€ ArXiv e-prints, Oct. 2014.
[11] N. Tishby, F. C. Pereira, and W. Bialek, â€œThe information bottleneck
in Proceedings of 37th Annual Allerton Conference on

method,â€
Communication, Control and Computing, 1999.

[8] N.Tishby and N.Zaslavsky, â€œDeep learning and the information bottle-

neck principle,â€ in Proc. of ITWâ€™15, 2015.

â€™00â€™â€™01â€™â€™10â€™â€™11â€™ğ‘‹ğ‘‹1ğ‘‹2= ğ‘Œ