6
1
0
2

 
r
a

M
 
4

 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
0
5
6
1
0

.

3
0
6
1
:
v
i
X
r
a

Learning Topology of the Power Distribution Grid

with and without Missing Data

*Electrical & Computer Engineering, University of Texas at Austin, â€ Los Alamos National Laboratory, USA

Deepjyoti Deka*, Scott Backhausâ€ , and Michael Chertkovâ€ 

Email: deepjyotideka@utexas.edu, backhaus@lanl.gov, chertkov@lanl.gov

1

Abstractâ€”Distribution grids refer to the part of the power grid
that delivers electricity from substations to the loads. Structurally
a distribution grid is operated in one of several radial/tree-like
topologies that are derived from an original loopy grid graph
by opening switches on some lines. Due to limited presence
of real-time switch monitoring devices, the operating structure
needs to be estimated indirectly. This paper presents a new
learning algorithm that uses only nodal voltage measurements
to determine the operational radial structure. The algorithm
is based on the key result stating that the correct operating
structure is the optimal solution of the minimum-weight spanning
tree problem over the original loopy graph where weights on
all permissible edges/lines (open or closed) is the variance of
nodal voltage difference at the edge ends. Compared to existing
work, this spanning tree based approach has signiï¬cantly lower
complexity as it does not require information on line parameters.
Further, a modiï¬ed learning algorithm is developed for cases
when the input voltage measurements are limited to only a subset
of the total grid nodes. Performance of the algorithms (with and
without missing data) is demonstrated by experiments on test
cases.

Index Termsâ€”Power Distribution Networks, Power Flows,
Spanning Tree, Graphical Models, Load estimation, Voltage
measurements, Missing data, Computational Complexity

I. INTRODUCTION

Distribution grids constitute the low voltage segment of
the power system delivering electricity from substations to
end-users. Both structurally and operationally the distribution
grids are distinct from the transmission (high voltage) portion
of the power system. A typical distribution grid is operated
as a collection of disjoint tree graphs, each growing from
substations at the root to customers. However, the complete
layout of the distribution system is loopy to allow multiple
alternatives for the trees to energize operationally. Switching
from one layout to another, implemented through switch on/off
devices placed on many segments of the distribution grid [1],
can take place rather often, in some cases few times an hour.
(See Fig. 1 for the illustration.) More frequent reconï¬guration
of the distribution is also promoted by recent in-mass inte-
gration of smart meters, PMUs [2] and smart devices, such as
deferrable loads and energy storage devices. Mixed operational
responsibilities in monitoring and operations, as well as the
growing role of the new smart devices and controls, make
fast and reliable estimation of the operational conï¬guration of
the distribution grid an important practical task, complicated
by the lack of real-time, line-based measurements. In such a
scenario, to estimate the distribution grid operational topology
one ought to rely only on nodal measurements of voltage and

end-user consumption. Notice, that brute force (combinatorial)
check of topologies for the nodal measurement consistency is
prohibitively expensive with the complexity growing exponen-
tially with the number of loops in the grid layout.

In this work we focus on beating the naive exponential
complexity of the operational topology learning task by explor-
ing power ï¬‚ow speciï¬c correlations between available nodal
measurements. In particular, we develop a spanning tree algo-
rithm that reconstructs the radial operational topology from
the original loopy layout by using functions of nodal voltage
magnitudes as edge weights. Computational complexity of this
algorithm is order O(nlogn) in the size of the loopy graphâ€™s
edge set. Moreover, the algorithm is generalized to the case
when some nodes are hidden.

A. Prior Work

Several approaches in the past have been made to learn
the topology of power grids under different operating condi-
tions and available measurements. [3] uses a Markov random
ï¬eld model for bus phase angles to build a dependency
graph to identify faults in the grids. [4] presents a topology
identiï¬cation algorithm for distribution grids that uses the
signs of elements in the inverse covariance matrix of voltage
measurements. [5] compares available time-series observations
from smart meters with a database of permissible signatures
to identify topology changes. This is similar to envelope
comparison schemes used in parameter estimation [6], [7].
For available line ï¬‚ow measurements, topology estimation
using maximum likelihood tests was analyzed in [8]. In our
own prior work [1], [9], we analyzed an iterative greedy
structure learning algorithm using trends in second order
moments of voltages. [9] also presented the ï¬rst attempt at
topology learning from incomplete voltage data where nodes
with missing voltages are separated by greater than two hops.
The aforementioned approaches are speciï¬c to power grid
graphs and typically not linked to research in probabilistic
Graphical Models (GM) [10] used to study statistics of im-
ages, languages, social networks, and communication schemes.
Learning generic (loopy) structures from pair-wise correlations
in a GM is a difï¬cult task, normally based on the maxi-
mal likelihood [10] with regularization for sparsity [11] and
greedy schemes utilizing conditional mutual information [12],
[13]. However, the GM-based learning simpliï¬es dramatically
when used, following the famous Chow-Liu approach [14],
to reconstruct the spanning tree maximizing edge-factorized

2

mutual information. [15] generalizes this technique to learn
tree structured GMs with latent variables (missing data) using
information distances as edge weights.

B. Contribution of This Work

Following [1], [9], we consider linear lossless AC power
ï¬‚ow models (also called, following [16], [17] Lin-Dist-Flow)
and assume that ï¬‚uctuations of consumption at the nodes are
uncorrelated. In this setting, our main result states that recon-
struction of the operating grid topology is equivalent to solving
the minimum weight spanning tree problem deï¬ned over the
loopy graph of the grid layout where edge weights are given by
variances in voltage magnitude differences across the edges.
We use this result to formulate the operating topology as a
spanning tree reconstruction problem that needs only empirical
voltage magnitude measurements as input. As spanning trees
can be efï¬ciently reconstructed, our learning algorithm has
much lower average and worst-case computational complexity
compared to existing techniques [4], [9]. While our algorithm
does not require knowing line impedances, these can be used
to estimate additionally statics of power consumption. Further,
we extend the topology learning algorithm to the case with
missing voltage data. The extension works provided nodes
with missing data are separated by at least two hops from
each other and covariances of nodal power consumption are
available. Compared to our prior work [9] on learning with
missing data, the spanning tree approach has lower complexity.
It also allows extension to cases with lesser restrictions on
missing data. Our algorithm shows some commonality with
the GM based spanning-tree learning of [15]. However the
key difference is that our approach relies principally on the
Kirchoffâ€™s laws of physical network ï¬‚ows contrary to the
measure of conditional independence utilized in [14], [15].
Thus, voltage magnitude based edge weights used in our work
are not restricted to satisfy graph additivity unlike information
distances in GM. Further, in the case with missing data, we
use power ï¬‚ow relations between nodal voltages and injections
that, to the best of our knowledge, do not have an analog in
GM learning literature. We highlight the performance of our
algorithm through experiments on test distribution grids for
both cases, with or without missing data.

The rest of the manuscript is organized as follows. Section II
introduces notations, nomenclature and power ï¬‚ow relations in
the distribution grids. Section III describes important features
of the nodal voltage magnitudes. This Section also contains
the proof of our main â€“ spanning tree learning/reconstruction
â€“ theorem. Algorithm reconstructing operational spanning tree
in the case of complete visibility (voltage magnitudes are
observed at all nodes) is discussed in Section IV. Modiï¬cation
of the algorithm which allows for some missing data (at the
nodes separated by at least two hopes) is described in Section
V. This Section also contains a brief discussion of some other
extensions/applications of our approach. Simulation results of
our learning algorithm on a test radial network are presented
in Section VI. Finally, Section VII contains conclusions and
discussion of future work.

Fig. 1.
A distribution grid with 4 substations (large red nodes). The
operational radial trees are formed by solid lines (black). Dotted grey lines
represent open switches. Non-substation nodes within each tree are marked
with the same color.

II. DISTRIBUTION GRID: STRUCTURE AND POWER FLOWS
Radial Structure: The original distribution grid is denoted
by the graph G = (V, E), where V is the set of buses/nodes of
the graph and E is the set of all undirected lines/edges (open
or operational). We denote nodes by alphabets (a, b,...) and
the edge connecting nodes a and b by (ab). The operational
grid has a â€˜radialâ€™ structure as shown in Fig. 1. In general, the
operational grid is a collection of K disjoint trees, âˆªi=1,Â·Â·Â· ,KTi
where each treeâ€™s root node has degree one (connected by one
edge) and represents a substation. In this paper, we will mainly
focus on grids where the operational structure consists of only
one tree T with nodes VT and operational edge set ET âŠ‚ E.
Generalization to the case with multiple disjoint trees will be
discussed along side major results.
Power Flow (PF) Models: Let zab = rab + ixab denote the
complex impedances of a line (ab) (i2 = âˆ’1). Here rab and
xab are line resistance and reactance respectively. Kirchhoffâ€™s
laws express the complex valued power injection at a node a
in tree T as

a âˆ’ vavb exp(iÎ¸a âˆ’ iÎ¸b)
v2

(1)

Pa = pa + iqa = âˆ‘

b:(ab)âˆˆET

zâˆ—
ab

where the real valued scalars, va, Î¸a, pa and qa denote the
voltage magnitude, voltage phase, active and reactive power
injection respectively at node a. Va(= va exp(iÎ¸a)) and Pa
denote the nodal complex voltage and injection respectively.
One node (substation/root node in our case) is considered as
reference and the voltage magnitude and phase at every non-
substation node are measured relative to the reference values.
As the complex power injection at the reference bus is given
by negation of the sum of injections at other buses, without
a loss of generality the analysis can be limited to a reduced
system, where one ignores reference substation bus voltages
and power injections. Under realistic assumption that losses of
both active and reactive power in lines of a distribution system
are small, Eq. (1) can be linearized as follows.

Linear Coupled (LC) model [1], [9]: In this model,
phase difference between neighboring nodes and magnitude
deviations (vaâˆ’1 = Îµa) from the reference voltage are assumed

3

Due to the radial topology of T, the inverse of the reduced
weighted graph Laplacian matrix H1/r has the following struc-
ture (see Section 4 in [1] for details).
âˆ‘
(cd)âˆˆPa

Hâˆ’1
1/r(a,b) =

(cid:84) Pb

rcd

(5)

T

T

Thus, the (a,b)th entry in Hâˆ’1
1/r is given by the sum of line
resistances of edges that are included in the path to the root
from either node as shown in Fig. 2. For nodes a and its parent
b in tree T (see Fig. 2), it follows from Eq. (5) that

(cid:40)

rab
0

Hâˆ’1
1/r(a,c)âˆ’ Hâˆ’1

1/r(b,c) =

if node c âˆˆ Da
otherwise,

T

(6)

We use Eqs. (5) and (6) to prove our results on voltage
magnitude relations. The results hold under the following
assumptions.

Assumption 1: Power Injection at different nodes are not
correlated, while active and reactive injections at the same
node are positively correlated. Mathematically, âˆ€a,b non-
substation nodes

â„¦qp(a,a) > 0, â„¦p(a,b) = â„¦q(a,b) = â„¦qp(a,b) = 0

Note that this is a valid assumption for many distribution grids
due to independence between different nodal load ï¬‚uctuations
and alignment/correlations between same nodeâ€™s active and
reactive power usage.

Under Assumption 1, we state the following result without

proof. (See [9] for details.)
Theorem 1.
of node b on tree T then â„¦Îµ(a,a) > â„¦Îµ(b,b).

[9, Theorem 1] If node a (cid:54)= b is a descendant

Next, we deï¬ne the term Ï†ab = E[(Îµa âˆ’ ÂµÎµa)âˆ’ (Îµb âˆ’ ÂµÎµb)]2,
which is the variance of the difference in voltage magnitudes
between nodes a and b.

Ï†ab = â„¦Îµ(a,a)âˆ’ 2â„¦Îµ(a,b) + â„¦Îµ(b,b)

(7)

(cid:16)

(Hâˆ’1

1/r(b,d))2â„¦p(d,d)

1/r(a,d)âˆ’ Hâˆ’1
(cid:17)

where â„¦Îµ is given by Eq. (4). Expressing Eq. (7) in terms of
the four matrices that constitute â„¦Îµ and then using Eq. (5)
leads to the following expansion of Ï†ab over power injections.
Ï†ab = âˆ‘
dâˆˆT
(cid:16)
1/x(a,d)âˆ’ Hâˆ’1
+ (Hâˆ’1
1/x(a,d)âˆ’ Hâˆ’1
Hâˆ’1
The next result identiï¬es trends in Ï†ab along the radial grid.
Note that the ï¬rst two cases in Lemma 1 are proven in [9].
The additional ï¬nal case is opposite of the ï¬rst case and helps
develop our new learning scheme presented later in this paper.
Lemma 1. For three nodes a (cid:54)= b (cid:54)= c in grid tree T, Ï†ab < Ï†ac
holds for the following cases:

1/x(b,d))2â„¦q(d,d) + 2
1/x(b,d)

1/r(a,d)âˆ’ Hâˆ’1
Hâˆ’1

â„¦pq(d,d)

(8)

(cid:17)

1/r(b,d)

1) Node a is a descendant of node b and node b is a

descendant of node c (see Fig. 3(a)).

2) Nodes a and c are descendants of node b and the path

from a to c passes through node b (see Fig. 3(b)).

The Figure shows distribution grid tree with substation/root node
Fig. 2.
colored in red. Here, nodes a and c are descendants of node a. Dotted lines
represent the paths from nodes a and d to the root node. The pathsâ€™ common
edges give Hâˆ’1

1/r(a,d) = rbe + re0.

to be small. The PF Eqs. (1) are linearized jointly over both
voltage magnitude and phase to give:
1/xq Î¸ = Hâˆ’1

1/x pâˆ’ Hâˆ’1
1/rq

1/r p + Hâˆ’1

Îµ = Hâˆ’1

(2)

Here, p,q,Îµ and Î¸ are the vectors of real power, reactive power,
voltage magnitude deviation and phase angle respectively at
the non-substation nodes of the reduced system. H1/r and H1/x
denote the reduced weighted Laplacian matrices for T where
reciprocal of resistances and reactances are used respectively
as edge weights. The reduced Laplacian matrices are of
full rank and constructed by removing the row and column
corresponding to the reference bus from the true Laplacian
matrix.

[1] shows that the LC-PF model is equivalent to the LinDis-
tFlow model [16]â€“[18], if deviations in voltage magnitude are
assumed to be small and thus ignored. (Notice, that if line
resistances are equated to zero, the LC-PF model reduces to
the DC PF model [19] used for transmission grids.) We can
express means (ÂµÎ¸,ÂµÎµ) and covariance matrices (â„¦Îµ,â„¦Î¸,â„¦Î¸Îµ)
of voltage magnitude deviations and phase angles in terms of
corresponding statistics of power injections using Eq. (2) as
shown below. Other quantities can be similarly determined.

ÂµÎ¸ = Hâˆ’1
â„¦Îµ = Hâˆ’1
+ Hâˆ’1

1/xÂµp âˆ’ Hâˆ’1
1/râ„¦pHâˆ’1
1/xâ„¦qpHâˆ’1

1/r

1/rÂµq, ÂµÎµ = Hâˆ’1
1/xâ„¦qHâˆ’1
1/r + Hâˆ’1

1/rÂµp + Hâˆ’1
1/xÂµq
1/râ„¦pqHâˆ’1
1/x + Hâˆ’1

1/x

(3)

(4)

In the next Section, we derive key results for functions of
nodal voltages in a radial distribution grid that will subse-
quently be used in the topology learning algorithm.

III. PROPERTIES OF VOLTAGE MAGNITUDES IN RADIAL

GRIDS

Consider grid tree T with operational edge set ET. Let Pa
T
denote the set of edges in the unique path from node a to the
root node (reference bus) in tree T. A node b is termed as a
descendant of node a if Pb
T includes some edge (ac) connected
to node a. We use Da
T to denote the set of descendants of a.
By deï¬nition, a âˆˆ Da
T. If b is an immediate descendant of a
((ab) âˆˆ ET), we term a as parent and b as its child. These
deï¬nitions are illustrated in Fig 2.

ğ‘ ğ‘ ğ‘ ğ‘‘ (ğ‘ğ‘) ğ‘’ (ğ‘ğ‘’) (ğ‘’0) (ğ‘‘ğ‘) 0 ğ·ğ‘ğ‘‡ğ‘˜ 4

(a)

(b)

(c)

Fig. 3. Distribution grid tree with substation/root node represented by large
red node. (a) Node a is a descendant of node b, node b is a descendant of
node c. (b) Node a and c are descendants of node b along disjoint sub-trees.
(a) Node c is a descendant of node b, node b is a descendant of node a.

3) Nodes c is a descendant of node b and node b is a

descendant of node a (see Fig. 3(c)).

T âˆ’ Pa

T âˆ’ Pa

T âŠ† Pc

T, where Pa

Proof: We give the proof for Case 3 depicted in Fig. 3(c).
In this case, Pb
T is the set of edges
in the unique path from node a to the root node of T. Further,
T âŠ† Da
the sets of descendants of a,b and c satisfy Dc
T.
From Fig. 3(c), it is clear that any node d belongs to either
Dc
T, Da
T, using
Eq. (5), we have,

T âŠ† Db
T. When d âˆˆ Dc

T or VT âˆ’ Da

T âˆ’ Db

T âˆ’ Dc

T, Db

T

T

T

T

<

(9)

(11)

(10)

â‡’ Hâˆ’1

For node d âˆˆ Db

1/r(a,d) = âˆ‘
re f < âˆ‘
re f
Tâˆ’Pa
(e f )âˆˆPc
Tâˆ’Pa
(e f )âˆˆPb
1/r(a,d) < Hâˆ’1
1/r(c,d)âˆ’ Hâˆ’1
1/r(a,d)
T, one derives
1/r(a,d) = âˆ‘
âˆ‘
re f
re f
(e f )âˆˆPb
Tâˆ’Pa
(e f )âˆˆPc
Tâˆ©Pd
Tâˆ’Pa
1/r(c,d)âˆ’ Hâˆ’1
1/r(a,d) < Hâˆ’1
1/r(a,d)

1/r(b,d)âˆ’ Hâˆ’1
Hâˆ’1
1/r(b,d)âˆ’ Hâˆ’1
T âˆ’ Dc
Hâˆ’1
1/r(b,d)âˆ’ Hâˆ’1
â‡’ Hâˆ’1
1/r(b,d)âˆ’ Hâˆ’1
T âˆ’ Db
For d âˆˆ Da
Hâˆ’1
1/r(b,d)âˆ’ Hâˆ’1
1/r(a,d) = âˆ‘
âˆ‘
re f =
re f
Tâˆ©Pd
Tâˆ©Pd
(e f )âˆˆPb
Tâˆ’Pa
(e f )âˆˆPc
Tâˆ’Pa
1/r(c,d)âˆ’ Hâˆ’1
1/r(a,d) = Hâˆ’1
1/r(b,d)âˆ’ Hâˆ’1
1/r(a,d)
(14)
1/r(a,d) = Hâˆ’1
T,Hâˆ’1
1/r(c,d)âˆ’
Finally for d âˆˆ T âˆ’ Da
1/r(a,d) = 0. Such inequalities also hold for Hâˆ’1
Hâˆ’1
1/x matrix.
Using the inequalities in Eqs. (10, 12,14) for Hâˆ’1
1/r and Hâˆ’1
1/x
with Eq. (8) results in Ï†ab < Ï†ac for Case 3. The proofs for
the other cases (1 and 2) can be done in a similar way and
they are thus skipped.

1/r(b,d)âˆ’ Hâˆ’1

T, one derives

â‡’ Hâˆ’1

(13)

(12)

T

T

Further, the following results hold for operational edges in

T.
Lemma 2. Let (ab) and (bc) be operational edges in T

1) If node a is the parent of node b (see Fig. 3(c)) then

Ï†ab = âˆ‘
r2
abâ„¦p(d,d) + x2
dâˆˆDb

T

abâ„¦q(d,d) + 2rabxabâ„¦pq(d,d)

2) If node b is the parent of node c and child of node a

(rab + rbc)2â„¦p(d,d) + (xab + xbc)2â„¦q(d,d)

T

(see Fig. 3(c)), then
Ï†ac = âˆ‘
dâˆˆDc
+ 2(rab + rbc)(xab + xbc)â„¦pq(d,d)
+âˆ‘
dâˆˆDb
> Ï†ab + Ï†bc

abâ„¦p(d,d) + x2
r2
Tâˆ’Dc

T

abâ„¦q(d,d) + 2rabxabâ„¦pq(d,d)

(15)

(16)

3) If node b is the parent of both nodes a and c (see

Fig. 3(b)), then
Ï†ac = âˆ‘
r2
abâ„¦p(d,d) + x2
dâˆˆDa
+âˆ‘
r2
bcâ„¦p(d,d) + x2
dâˆˆDc
= Ï†ab + Ï†bc

T

T

abâ„¦q(d,d) + 2rabxabâ„¦pq(d,d)

bcâ„¦q(d,d) + 2rbcxbcâ„¦pq(d,d)

Proof:

1) We use Eq. (6) in Eq. (8) as (ab) is an edge.
2) We follow the proof in Lemma 1. The result holds as the
left sides of Eqs. (9),(11),(13) here are given by (rab +
rbc), rab and 0 respectively. The inequality in (15) is
derived by applying Statement 1 for edges (ab) and (bc)
and noting that (y1 + y2)âˆ— (y3 + y4) > y1y3 + y2y4 holds
for positive reals y1,y2,y3,y4.

3) We use the same technique as above. Here Dc

T and Da
T
are disjoint. Using this fact along with Eq. (6) for edges
(ab) and (bc) results in the equality (16).

It is worth mentioning that all three statements in Lemma 2
involve line impedances corresponding to edges (ab) and (bc)
only. In the following sections, we use these results to design
our topology learning algorithm.

IV. STRUCTURE LEARNING WITH FULL OBSERVATION
Our main result for topology learning using voltage magni-

tude measurements is formulated using Lemma 1.
Theorem 2. Let the weight of each permissible edge (ab) âˆˆ
E of the original loopy graph be Ï†ab = E[(Îµa âˆ’ ÂµÎµa)âˆ’ (Îµb âˆ’
ÂµÎµb)]2. Then operational edge set ET in radial grid T forms
the minimum weight spanning tree of the original graph.

Proof: From Lemma 1, it is clear that for each node a, the
minimum value of Ï†ab along any path in T (towards or away
from the root node) is attained at its immediate neighbor b
on that path, connected by edge (ab) âˆˆ ET. The minimum
spanning tree for the original loopy graph with Ï†â€™s as edge
weights is thus given by the operational edges in the radial
tree.

Note that if node a is taken as the substation/root node (Îµa =
0), the weight of any edge (ab) is given by Ï†ab = â„¦Îµ(b,b).
As mentioned in Section II, the substation has one child. In
the spanning tree construction, the root is thus connected to
the node with lowest variance of voltage magnitude. This is
in agreement with Theorem 1.

ğ‘ ğ‘ ğ·ğ‘ğ‘‡ğ‘˜ ğ·ğ‘ğ‘‡ğ‘˜ ğ·ğ‘ğ‘‡ğ‘˜ ğ‘ ğ‘ ğ‘ ğ·ğ‘ğ‘‡ğ‘˜ ğ·ğ‘ğ‘‡ğ‘˜ ğ‘ ğ·ğ‘ğ‘‡ğ‘˜ ğ‘ ğ‘ ğ·ğ‘ğ‘‡ğ‘˜ ğ·ğ‘ğ‘‡ğ‘˜ ğ‘ ğ·ğ‘ğ‘‡ğ‘˜ Algorithm 1: The input consists of voltage magnitude read-
ings for all non-substation buses in the system. An observer
computes Ï†ab for all permissible edges (ab) âˆˆ E (including
those with the root node) and identiï¬es edges in the minimum
spanning tree as the set of operational edges ET. The root node
is restricted to have a single edge. Note that Algorithm 1 does
not need any information on line parameters (resistances and
reactances) or on statistics of active and reactive nodal power
consumption. If impedances of lines in E and phase angle
measurements at all nodes are known, Eqs. (2), (3) and (4)
can be used to estimate means and covariances of each nodeâ€™s
power injection.

Algorithm 1 Minimum Weight Spanning Tree based Topology
Learning
Input: m voltage magnitude deviations Îµ for all nodes, set of
all edges T.
Output: Operational Edge set ET.
1: âˆ€(ab)inE, compute Ï†ab = E[(Îµa âˆ’ ÂµÎµa)âˆ’ (Îµb âˆ’ ÂµÎµb)]2
2: Find minimum weight spanning tree from E with Ï†ab as
3: ET â† edges in spanning tree

edge weights. Limit degree of substation to 1.

Algorithm Complexity: Using Kruskalâ€™s Algorithm [20],
[21], the minimum spanning tree from E edges can be com-
puted in O(|E|log|E|) operations. This is a great improvement
over previous iterative or matrix inversion based techniques
which scaled as O(N3), where N = |VT| is the number of
nodes in the grid. If E is not known or corresponds to the
complete graph, Algorithm 1â€™s complexity is O(N2 logN), i.e.
it still compares favorably with the prior scheme.

Extension to Multiple Trees: If multiple trees exist in the
grid, voltage magnitudes at nodes a and b belonging to disjoint
trees will be independent. Thus, Ï†ab = â„¦Îµ(a,a)+â„¦Îµ(b,b). This
result can be used to separate nodes into disjoint groups before
running Algorithm 1 to generate the operational tree in each
group.

In the next Section, we extend our spanning tree based
algorithm to consider cases where information is missing at
some fraction of nodes.

V. STRUCTURE LEARNING WITH MISSING DATA

In a realistic power grid, communication packet drops or
random noise events may erase voltage magnitude measure-
ments for node set M in T. Following [9], we consider
arbitrary placement of unobserved nodes with the following
restriction.

Assumption 2: Missing nodes are separated by greater than

two hops in the grid tree T.

Note that under assumption 1, an observable node cannot
be connected to two or more unobserved nodes. (We plan
to analyze extensions beyond Assumption 2 in future work.)
Additionally, we assume that the adversary estimates or has
access to historical information for the values of â„¦p, â„¦q and
â„¦pq covariance matrices for all nodes and impedances of all
possible lines in E.

5

(a)

(b)

(c)

(a)Distribution grid tree T with unobserved leaf node l non-
Fig. 4.
leaf unobserved node b. Node a is bâ€™s parent while nodes c1,c2,c3,c4 are
its children. The spanning tree TM of observed nodes exists in either (b)
Conï¬guration A or (c) Conï¬guration B as per Theorem 3

To reconstruct operational topology in the presence of miss-
ing data, we ï¬rst construct the minimum weight observable
spanning tree TM using Ï†ab = E[(Îµa âˆ’ ÂµÎµa)âˆ’ (Îµb âˆ’ ÂµÎµb)]2 as
edge weights between observable nodes. We then analyze
edges in tree TM and detect unobserved node locations.
Consider the situation shown in Fig. 4(a) where information
from the leaf node l is missing. By Assumption 2, information
from its parent (q) and grandparent (w) are observed in TM.
Note that Ï†qw satisï¬es Statement 1 in Lemma 2. If all other
descendants of q are known, statement 1 of the Lemma can
be used to identify the existence of unobserved node l.

Tâˆ’{b} Ï†ad âˆˆ C and argmindâˆˆVTâˆ’Db

We now discuss the identiï¬cation of a non-leaf node with
missing information. Assume that information is missing at
the node b in Fig. 4(a). bâ€™s parent a and children node set
C = {c1,c2,c3,c4} comprise its one-hop neighborhood, and
are observable under Assumption 2. Using Cases 1 and 3 in
Ï†cid =
Lemma 1, argmindâˆˆDb
aâˆ€ci âˆˆ C. Thus, descendants of b are connected to the rest
of TM through edges between its one-hop neighbors (set C
and a). The following theorem gives the edge conï¬gurations
possible in TM for a and nodes in C.
Theorem 3. Let argminciâˆˆC Ï†bci = câˆ—. No edge (cic j) between
children nodes ci,c j (cid:54)= câˆ— exists in TM. All nodes in set C1 =
{ci âˆˆ C,Ï†aci < Ï†câˆ—ci} are connected to node a, while all nodes
in C2 = Câˆ’ C1 are connected to câˆ—.

T

Proof: Consider any node pair ci,c j (cid:54)= câˆ— in C. Using
Eq. (16) in Lemma 2 and deï¬nition of câˆ—, Ï†cic j = Ï†bci +Ï†bc j <
Ï†bci + Ï†bcâˆ— = Ï†cicâˆ—. Thus, any possible edge between children
nodes must include node câˆ—. The edges for each node in sets
C1 and C2 follow immediately by comparing weights with câˆ—
and a.
Theorem 3 does not specify if edge (acâˆ—) exists in TM. In
fact node câˆ— will be connected to a node câ€  âˆˆ C1 instead of
a if Ï†acâ€  < Ï†câˆ—câ€  < Ï†acâˆ— holds. There are thus two permissible
conï¬gurations A and B (see Figs. 4(b), 4(c)) in TM for con-
nections between one hop neighbors of non-leaf unobservable
node b. Note that one of sets C1 or C2 may be empty as well.
Any two nodes in C are children of node b and thus satisfy
Statement 3 in Lemma 2. Observe that for both conï¬gurations
A and B, this result holds for câˆ— and any of its children in TM

ğ‘ ğ‘1 ğ‘ ğ‘3 ğ‘2 ğ‘4 ğ‘™ ğ‘ ğ‘¤ ğ‘ ğ‘1 câˆ—= ğ‘3 ğ‘2 ğ‘4 ğ‘ ğ‘¤ ğ‘ ğ‘1 câˆ—= ğ‘3 ğ‘ 2 ğ‘4 ğ‘ ğ‘¤ 6

that belong to C. The result also holds for câˆ— and its parent in
conï¬guration B. On the other hand, any node in C and a are
actually separated by node b and thus it satisï¬es Statement 2
in Lemma 2. This result thus holds for node a and any of its
children from C. Statements 2 and 3 in Lemma 2 can hence
be used to identify unobservable node b in Algorithm 2.
Algorithm 2: Assume that information is missing at the set
M, thus leaving only VT âˆ’ M observable. Covariance matrices
for power injection at all nodes of the observed set are assumed
known to the observer along with impedances of all lines in E.
Algorithm 2, ï¬rst, constructs spanning tree TM for observed
nodes using edge weights for all node combinations given
by Ï†. Observed nodes in TM are then arranged in reverse
topological order (decreasing depth from root node). This is
done as unobserved node locations are iteratively searched
from leaf sites inward towards the root (see Step 5). For each
leaf b with parent a, Steps 7 to 12 checks if edge (ab) âˆˆ ET
with or without some unobserved leaf node h connected to
b. For undecided nodes in C, the Algorithm ï¬rst checks for
conï¬guration A or B described in the preceding discussion.
Step 15 determines if nodes in C and a are separated by a
unobserved node h using Statement 2 in Lemma 2. If such a
node doesnâ€™t exist, Step 18 search for a unobserved node that is
parent of both nodes in C and node a using using Statement 3
in Lemma 2. Nodes a and set C are removed from the observed
tree TM in each iteration and discovered edges are added to
ET. Further, injection covariances at the recently identiï¬ed
descendants are added for use in later checks involving results
from Lemma 2. Note that only in the ï¬nal case (Step 18), the
unobserved node h is not removed from set M as its parent
node has not been determined yet. This process is iterated by
picking a new node a with all children as leaf nodes until no
nodes with missing information remain to be discovered.
Complexity: Computing the spanning tree for observed
nodes has complexity O((N âˆ’ |M|)2 log(N âˆ’ |M|)). Sorting
observed nodes in topological order is done in linear time
(O(N âˆ’ |M|)) [21]. Finally, checking (Steps 5, 7, 12, 15)
for all iterations has complexity O((N âˆ’ |M|)|M|) as total
observed nodes and edges number O((Nâˆ’|M|)) and searching
over unobserved nodes takes at most |M| steps. The overall
complexity of Algorithm 2 is thus O((N âˆ’ |M|)2 log(N âˆ’
|M|) + (N âˆ’|M|)|M|) which is O(N2 logN) in the worst case.
Note that this is also the worst-case complexity of Algorithm
1.

Relation to Learning Probabilistic Graphical Model: It is
worth noting that in the tree-structured GM learning [15], edge
(acâˆ—) always exists due to the graph-additivity of edge weights
and conï¬guration B in Fig. 4(c) is not realized. The inequality
in Eq. (15) of Lemma 2 shows that Ï† may be strictly increasing
with the number of graph hops and thus it does not satisfy
graph additivity in general. Non-additivity of edge weights
makes our topology learning approach a generalization of the
additive model in [15] .

Extensions: We brieï¬‚y mention two extensions of Algo-
rithm 2, planning to analyze these in details in the future.
First, Algorithm 2 can be used for structure learning when
injection covariances at unobserved nodes are not known.
Here each unobserved node must have at least two children for

Fig. 5.
Layouts of the grids tested. The red circle represents substation
(marked as S). The blue circles represent numbered load nodes. Black lines
represent operational edges. The additional open lines are represented by
dotted green lines.

unique identiï¬cation. Second, Algorithm 2 will be extended to
operate when unobserved nodes are separated by 2 hops. In
this case, permissible conï¬gurations in addition to A and B
(see Fig. 4) need to be checked. A modiï¬cation of Statement
2 in Lemma 2 will be used to detect unobserved nodes. In the
following Section, we discuss the performance of our designed
algorithms through experiments on test networks.

VI. EXPERIMENTS

Here we demonstrate performance of Algorithm 1 in de-
termining the operational edge set ET of the radial grid T.
We consider a radial network [22], [23] with 29 load nodes
and one substation as shown in Fig. 5. In each of our simula-
tion runs, we ï¬rst collect complex power injection samples
at
the non-substation nodes from a multivariate Gaussian
distribution that is uncorrelated between different nodes as
per Assumption 1. We use LC-PF model to generate nodal
voltage magnitude measurements. Finally, we introduce 30
additional edges (at random) forming the loopy edge set E. The
additional edges are given random impedances comparable
to those of operational lines. We, ï¬rst, test performance of
the Algorithm 1 for the case where locations of edges in
the set E and voltage magnitude measurements at all non-
substation nodes are available. We show results for topology
learning for this case in Fig. 6(a). Note that the estimation
is extremely accurate and average errors expressed relative
to the size of the operational edge set) decay to zero at
the sample sizes less than 50. We also estimate covariance
matrices of complex nodal power injections using the just
reconstructed radial operating topology and plot results in
Fig. 6(b). For covariance estimation, line impedances of the
set E and samples of phase angle measurements are used along
with voltage magnitude samples as input. The relative errors
in this case decay exponentially with increase in the number
of the measurement samples.

Next, we present simulations for Algorithm 2 where the
operational grid structure is reconstructed in the presence of
unobserved nodes. We consider three cases with information at
the nodes 4, 6 and 8 missing. The location of the unobserved
nodes are selected at random in accordance with Assumption

S12345678910111213141516171819202122232425262728297

Algorithm 2 Minimum Weight Spanning Tree based Topology learning with Missing Data
Input: Injection covariances â„¦p,â„¦q,â„¦pq of all nodes, Missing nodes Set M, m voltage deviation observations Îµ for nodes in
VT âˆ’ M, set of all edges T with line impedances.
Output: Operational Edge set ET.
1: âˆ€ observable nodes a,b, compute Ï†ab = E[(Îµa âˆ’ ÂµÎµa)âˆ’ (Îµb âˆ’ ÂµÎµb)]2
2: Find minimum weight spanning tree TM with Ï†ab as edge weights. Limit degree of substation to 1.
3: Sort nodes in TM in reserve topological order.
4: while |M| > 0 do
Select node a whose children set C in TM consists only of leaf nodes
5:
for all b âˆˆ C do
6:
7:
8:
9:
10:
11:

ET â† ET âˆª{(ab), (bh)}, M â† Mâˆ’{h}, C â† Câˆ’{b}, Add injection covariance of b and h to a. Remove node

ET â† ET âˆª{(ab)}, C â† Câˆ’{b}, Add injection covariance of b to a. Remove node b from TM.

end if
if âˆƒh âˆˆ M s..t. Ï†ab satisfy Statement 1 in Lemma 2 with Db

if Ï†ab satisfy Statement 1 in Lemma 2 with Db

T = {b,h} then

T = {b} then

b from TM.
end if

end for
if |C| > 0 then

nodes in C from TM.

else

12:
13:
14:
15:
16:

17:
18:
19:

in C from TM.
end if

20:
end if
21:
22: end while

if âˆƒb âˆˆ C,h âˆˆ M s..t. Ï†ab satisfy Statement 2 in Lemma 2 with Db

T = {b} and Dh

T = {h}âˆª C then

ET â† ET âˆª{(ah)}âˆª{(ch)âˆ€c âˆˆ C}, M â† Mâˆ’{h}, C â† /0, Add injection covariances âˆ€c âˆˆ C and h to a. Remove

Pick b âˆˆ C. Find h âˆˆ M s..t. Ï†ab satisfy Statement 3 in Lemma 2 with h as parent and Db
T = {a}.
ET â† ET âˆª{(ah)}âˆª{(ch)âˆ€c âˆˆ C}, C â† /0, Add injection covariances of a and âˆ€c âˆˆ C to h. Remove a and nodes

T = {b} , Da

2. Voltage magnitudes at the unobserved nodes are removed
from the input data. Covariance of power injections at all the
load nodes and impedances of all the lines within the loopy
edge set E are provided as input to the observer. The average
number of errors shown in Fig. 7(a) decreases steadily with
increase in the number of samples. This tendency is seen
clearly for all the cases of the unobserved node sets. Further,
the average errors increase with increase in the number of
unobserved nodes for a ï¬xed number of measurement samples.
The average errors produced by Algorithm 2 are signiï¬cantly
lower in comparison with the respective algorithm from [9],
however (and as expected) the Algorithm is signiï¬cantly less
accurately than Algorithm 1 where all nodes are observed.

VII. CONCLUSIONS

Identifying the operational edges in the distribution grids
is critical for real-time control and reliable management of
different grid operations. In this paper, we study the problem
of learning the radial operating structure from a dense loopy
grid graph. Under an LC (linear coupled) power ï¬‚ow model,
we show that if edge weights between load nodes are deï¬ned
as the variance of the difference of their voltage magnitudes,
the minimum weight spanning tree optimization over the
loopy physical
layout outputs operational radial structure.
Using this spanning tree property, we design a fast structure
learning algorithm that uses only nodal voltage magnitude

measurements for the input. We then extend the spanning
tree based framework to learn the operational structure when
available voltage measurements are limited to a subset of the
grid nodes. For unobserved nodes separated by greater than
three hops, the learning algorithm is able to identify locations
of the missing measurements by verifying properties of our
voltage magnitude based edge weights. In this case, statistics
of nodal injections and line impedances are used as a part of
the input. We demonstrate good performance of the learning
algorithm through experiments on distribution grid test cases.
Finally, we discuss how voltage magnitude based edge weights
in our algorithm generalizes edge metrics used in learning
schemes of probabilistic GMs. In future we plan to generalize
our approach reducing restrictions, e.g. allowing unobserved
nodes to be separated by less than two hops and utilizing less
information about nodal consumption.

REFERENCES

[1] D. Deka, S. Backhaus, and M. Chertkov, â€œStructure learning and
statistical estimation in distribution networks - part i,â€ arXiv preprint
arXiv:1501.04131, 2015.

[2] A. Phadke, â€œSynchronized phasor measurements in power systems,â€

Computer, 1993.

[3] M. He and J. Zhang, â€œA dependency graph approach for fault detection
and localization towards secure smart grid,â€ Smart Grid, IEEE Transac-
tions on, vol. 2, no. 2, pp. 342â€“351, 2011.

[4] S. Bolognani, N. Bof, D. Michelotti, R. Muraro, and L. Schenato, â€œIden-
tiï¬cation of power distribution network topology via voltage correlation

analysis,â€ in Decision and Control (CDC), 2013 IEEE 52nd Annual
Conference on.

IEEE, 2013, pp. 1659â€“1664.

[5] G. Cavraro, R. Arghandeh, A. von Meier, and K. Poolla, â€œData-driven
approach for distribution network topology detection,â€ arXiv preprint
arXiv:1504.00724, 2015.

[6] J. Peppanen, J. Grimaldo, M. J. Reno, S. Grijalva, and R. G. Harley, â€œIn-
creasing distribution system model accuracy with extensive deployment
of smart meters,â€ in PES General Meetingâ€” Conference & Exposition,
2014 IEEE.

IEEE, 2014, pp. 1â€“5.

[7] J. Peppanen, M. J. Reno, M. Thakkar, S. Grijalva, and R. G. Harley,
â€œLeveraging ami data for distribution system model calibration and
situational awareness,â€ 2015.

[8] R. Sevlian and R. Rajagopal, â€œFeeder topology identiï¬cation,â€ arXiv

preprint arXiv:1503.07224, 2015.

[9] D. Deka, S. Backhaus, and M. Chertkov, â€œStructure learning and
statistical estimation in distribution networks - part ii,â€ arXiv preprint
arXiv:1502.07820, 2015.
[10] M. J. Wainwright and M. I. Jordan, â€œGraphical models, exponential fam-
ilies, and variational inference,â€ Foundations and Trends R(cid:13) in Machine
Learning, vol. 1, no. 1-2, pp. 1â€“305, 2008.

[11] P. Ravikumar, M. J. Wainwright, J. D. Lafferty et al., â€œHigh-dimensional
ising model selection using 1-regularized logistic regression,â€ The An-
nals of Statistics, vol. 38, no. 3, pp. 1287â€“1319, 2010.

[12] A. Anandkumar, V. Tan, and A. S. Willsky, â€œHigh-dimensional graphical
model selection: tractable graph families and necessary conditions,â€ in
Advances in Neural Information Processing Systems, 2011, pp. 1863â€“
1871.

[13] P. Netrapalli, S. Banerjee, S. Sanghavi, and S. Shakkottai, â€œGreedy
learning of markov network structure,â€ in Communication, Control, and
Computing (Allerton), 2010 48th Annual Allerton Conference on. IEEE,
2010, pp. 1295â€“1302.

[14] C. Chow and C. Liu, â€œApproximating discrete probability distributions
with dependence trees,â€ Information Theory, IEEE Transactions on,
vol. 14, no. 3, pp. 462â€“467, 1968.

[15] M. J. Choi, V. Y. Tan, A. Anandkumar, and A. S. Willsky, â€œLearning la-
tent tree graphical models,â€ The Journal of Machine Learning Research,
vol. 12, pp. 1771â€“1812, 2011.

[16] M. Baran and F. Wu, â€œOptimal sizing of capacitors placed on a radial
distribution system,â€ Power Delivery, IEEE Transactions on, vol. 4,
no. 1, pp. 735â€“743, Jan 1989.

[17] â€”â€”, â€œOptimal capacitor placement on radial distribution systems,â€
Power Delivery, IEEE Transactions on, vol. 4, no. 1, pp. 725â€“734, Jan
1989.

[18] â€”â€”, â€œNetwork reconï¬guration in distribution systems for loss reduction
and load balancing,â€ Power Delivery, IEEE Transactions on, vol. 4, no. 2,
pp. 1401â€“1407, Apr 1989.

[19] A. Abur and A. G. Exposito, Power system state estimation: theory and

implementation. CRC Press, 2004.

[20] J. B. Kruskal, â€œOn the shortest spanning subtree of a graph and the
traveling salesman problem,â€ Proceedings of the American Mathematical
society, vol. 7, no. 1, pp. 48â€“50, 1956.

[21] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction

to Algorithms. The MIT Press, 2001.

[22] U. Eminoglu and M. H. Hocaoglu, â€œA new power ï¬‚ow method for radial
distribution systems including voltage dependent load models,â€ Electric
Power Systems Research, vol. 76, no. 13, pp. 106 â€“ 114, 2005.

[23] [Online]. Available: http://www.dejazzer.com/reds.html

8

(a)

(b)

Fig. 6. Average fractional errors vs number of samples used in Algorithm 1
for (a) Learning operational edges (c) Estimating nodal injection covariances.

(a)

Fig. 7. Average fractional errors in learning operational edges vs number of
samples used in Algorithm 2 with missing data. Information is missing at the
nodes 4,6 and 8.

2040608010012014016018020000.511.522.533.5x 10âˆ’4number of measurement samplesAverage relative error in learning operational edges204060801001201401601802000.050.10.150.20.250.3number of measurement smaplesAverage relative error in estimating nodal injection covariances20040060080010001200140016001800200000.050.10.150.20.250.30.350.40.45number of measurement samplesAverage relative error in  learning operational edges   4 missing nodes6 missing nodes8 missing nodes